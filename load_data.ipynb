{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d4c6328",
   "metadata": {},
   "source": [
    "# Backblaze Data Pipeline - S3 Setup and Data Loading\n",
    "\n",
    "This notebook sets up an S3 bucket, downloads Backblaze hard drive data, and converts it to partitioned Parquet format for efficient querying.\n",
    "\n",
    "## 1. Initialize S3 Bucket\n",
    "\n",
    "Creates or retrieves an S3 bucket for storing raw and curated data. The bucket name is persisted in a `.env` file for reuse across sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43983a8e-a5ca-49f5-9ee6-57d4dfc8e9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing bucket from .env: mlops-backblaze-d7b30cb5-us-east-1\n",
      "Bucket ready: mlops-backblaze-d7b30cb5-us-east-1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import boto3\n",
    "from dotenv import load_dotenv, set_key\n",
    "\n",
    "ENV_PATH = \".env\"\n",
    "\n",
    "# Load .env if it exists\n",
    "load_dotenv(ENV_PATH)\n",
    "\n",
    "bucket = os.getenv(\"BUCKET_NAME\")\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "s3 = boto3.client(\"s3\", region_name=region)\n",
    "\n",
    "# If BUCKET_NAME exists, use it\n",
    "if bucket:\n",
    "    print(\"Using existing bucket from .env:\", bucket)\n",
    "\n",
    "else:\n",
    "    # Create new bucket name\n",
    "    bucket = f\"mlops-backblaze-{uuid.uuid4().hex[:8]}-{region}\"\n",
    "    print(\"Creating new bucket:\", bucket)\n",
    "\n",
    "    if region == \"us-east-1\":\n",
    "        s3.create_bucket(Bucket=bucket)\n",
    "    else:\n",
    "        s3.create_bucket(\n",
    "            Bucket=bucket,\n",
    "            CreateBucketConfiguration={\"LocationConstraint\": region}\n",
    "        )\n",
    "\n",
    "    # Persist to .env\n",
    "    if not os.path.exists(ENV_PATH):\n",
    "        open(ENV_PATH, \"w\").close()\n",
    "\n",
    "    set_key(ENV_PATH, \"BUCKET_NAME\", bucket)\n",
    "\n",
    "print(\"Bucket ready:\", bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9832ee59",
   "metadata": {},
   "source": [
    "## 2. Create Folder Structure\n",
    "\n",
    "Creates a standard MLOps folder structure in S3 to organize:\n",
    "- Raw data (Backblaze hard drive stats, reviews)\n",
    "- Curated/processed data\n",
    "- Feature stores\n",
    "- Model artifacts\n",
    "- Evaluation results\n",
    "- Monitoring data\n",
    "- Batch inference outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d4fa7e-bd95-46ee-bcaa-a3344a97f221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder layout created:\n",
      " - raw/backblaze/\n",
      " - raw/reviews/\n",
      " - curated/\n",
      " - features/\n",
      " - artifacts/models/\n",
      " - artifacts/eval/\n",
      " - artifacts/monitoring/\n",
      " - inference/batch/\n"
     ]
    }
   ],
   "source": [
    "# prefixes = [\n",
    "#     \"raw/backblaze/\",\n",
    "#     \"raw/reviews/\",\n",
    "#     \"curated/\",\n",
    "#     \"features/\",\n",
    "#     \"artifacts/models/\",\n",
    "#     \"artifacts/eval/\",\n",
    "#     \"artifacts/monitoring/\",\n",
    "#     \"inference/batch/\"\n",
    "# ]\n",
    "\n",
    "# for p in prefixes:\n",
    "#     s3.put_object(Bucket=bucket, Key=p)\n",
    "\n",
    "# print(\"Folder layout created:\")\n",
    "# for p in prefixes:\n",
    "#     print(\" -\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21545a3a",
   "metadata": {},
   "source": [
    "## 3. Verify Folder Structure\n",
    "\n",
    "Lists all objects in the S3 bucket to confirm the folder structure was created successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd5e3eae-8202-4219-a984-5101e9bf9842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifacts/eval/\n",
      "artifacts/models/\n",
      "artifacts/monitoring/\n",
      "curated/\n",
      "features/\n",
      "inference/batch/\n",
      "raw/backblaze/\n",
      "raw/backblaze/zips/data_Q1_2024.zip\n",
      "raw/backblaze/zips/data_Q1_2025.zip\n",
      "raw/backblaze/zips/data_Q2_2024.zip\n",
      "raw/backblaze/zips/data_Q2_2025.zip\n",
      "raw/backblaze/zips/data_Q3_2024.zip\n",
      "raw/backblaze/zips/data_Q3_2025.zip\n",
      "raw/backblaze/zips/data_Q4_2024.zip\n",
      "raw/reviews/\n",
      "raw/reviews_2023_parquet/raw_review_Electronics/part-000000.parquet\n"
     ]
    }
   ],
   "source": [
    "resp = s3.list_objects_v2(Bucket=bucket)\n",
    "for obj in resp.get(\"Contents\", []):\n",
    "    print(obj[\"Key\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d9f2c7",
   "metadata": {},
   "source": [
    "## 4. Download Backblaze Data to S3\n",
    "\n",
    "Scrapes the Backblaze website to find all quarterly data files from 2024 onwards, then:\n",
    "- Downloads each ZIP file directly from Backblaze\n",
    "- Streams the data to S3 without storing locally (efficient for large files)\n",
    "- Skips files that already exist in S3 to avoid redundant downloads\n",
    "- Stores ZIP files in `raw/backblaze/zips/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23a20ee4-0351-4641-95f6-ef4301917a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found URLs:\n",
      "3 backblaze_2025_plus_urls.txt\n",
      "https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q1_2025.zip\n",
      "https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q2_2025.zip\n",
      "https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q3_2025.zip\n",
      "Skip: data_Q1_2025.zip\n",
      "Skip: data_Q2_2025.zip\n",
      "Skip: data_Q3_2025.zip\n",
      "Done. Uploaded files in:\n",
      "2026-01-25 13:42:10 1020483699 data_Q1_2025.zip\n",
      "2026-01-25 13:43:05 1067562257 data_Q2_2025.zip\n",
      "2026-01-25 13:44:03 1111587745 data_Q3_2025.zip\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -e\n",
    "\n",
    "BUCKET=\"mlops-backblaze-d7b30cb5-us-east-1\"\n",
    "\n",
    "curl -s https://www.backblaze.com/cloud-storage/resources/hard-drive-test-data \\\n",
    "  | grep -Eo 'https://f001\\.backblazeb2\\.com/file/Backblaze-Hard-Drive-Data/data_Q[1-4]_[0-9]{4}\\.zip' \\\n",
    "  | grep -E '_202[5-9]\\.zip' \\\n",
    "  | sort -u > backblaze_2025_plus_urls.txt\n",
    "\n",
    "echo \"Found URLs:\"\n",
    "wc -l backblaze_2025_plus_urls.txt\n",
    "head -n 5 backblaze_2025_plus_urls.txt\n",
    "\n",
    "while read -r url; do\n",
    "  fname=$(basename \"$url\")\n",
    "\n",
    "  # Skip if already in S3\n",
    "  if aws s3 ls \"s3://$BUCKET/raw/backblaze/zips/$fname\" >/dev/null 2>&1; then\n",
    "    echo \"Skip: $fname\"\n",
    "    continue\n",
    "  fi\n",
    "\n",
    "  echo \"Streaming upload: $fname\"\n",
    "  wget -qO- \"$url\" | aws s3 cp - \"s3://$BUCKET/raw/backblaze/zips/$fname\"\n",
    "done < backblaze_2025_plus_urls.txt\n",
    "\n",
    "echo \"Done. Uploaded files in:\"\n",
    "aws s3 ls \"s3://$BUCKET/raw/backblaze/zips/\" | head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122f88a5",
   "metadata": {},
   "source": [
    "## 5. List Downloaded ZIP Files\n",
    "\n",
    "Verifies that all ZIP files were successfully uploaded to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "246621ee-6c6b-449a-a3c2-41800c04fa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-25 13:42:10 1020483699 data_Q1_2025.zip\n",
      "2026-01-25 13:43:05 1067562257 data_Q2_2025.zip\n",
      "2026-01-25 13:44:03 1111587745 data_Q3_2025.zip\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "BUCKET=\"mlops-backblaze-d7b30cb5-us-east-1\"\n",
    "aws s3 ls \"s3://$BUCKET/raw/backblaze/zips/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b966074",
   "metadata": {},
   "source": [
    "## 6. List and Prepare ZIP Files for Processing\n",
    "\n",
    "Imports libraries for data processing and lists all ZIP files from S3 that need to be converted to Parquet format. Uses pagination to handle large numbers of files efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33ffcf69-ed43-439c-bae0-e1ad343374ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIPs found: 3\n",
      "['raw/backblaze/zips/data_Q1_2025.zip', 'raw/backblaze/zips/data_Q2_2025.zip', 'raw/backblaze/zips/data_Q3_2025.zip']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "\n",
    "zip_s3_prefix = \"raw/backblaze/zips/\"\n",
    "out_prefix = \"curated/backblaze_parquet/\"\n",
    "\n",
    "# s3 = boto3.client(\"s3\")\n",
    "\n",
    "def list_s3_keys(prefix):\n",
    "    paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "    keys = []\n",
    "    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "        for obj in page.get(\"Contents\", []):\n",
    "            if obj[\"Key\"].endswith(\".zip\"):\n",
    "                keys.append(obj[\"Key\"])\n",
    "    return sorted(keys)\n",
    "\n",
    "zip_keys = list_s3_keys(zip_s3_prefix)\n",
    "print(\"ZIPs found:\", len(zip_keys))\n",
    "print(zip_keys[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522fbf59",
   "metadata": {},
   "source": [
    "## 7. Convert CSV to Partitioned Parquet\n",
    "\n",
    "Processes each ZIP file by:\n",
    "1. Downloading the ZIP from S3 into memory\n",
    "2. Extracting CSV files from the ZIP\n",
    "3. Parsing date information from CSV filenames (YYYY-MM-DD)\n",
    "4. Converting CSV to Parquet format with Snappy compression\n",
    "5. Uploading to S3 with Hive-style partitioning: `year=YYYY/month=MM/day=DD/`\n",
    "6. Skipping files that already exist to enable resumable processing\n",
    "\n",
    "This partitioned structure enables efficient querying by date ranges in tools like Athena or Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "289feb89-baac-45f0-be3c-4a88961a24d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: raw/backblaze/zips/data_Q1_2025.zip\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=01/data_Q1_2025_01.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=02/data_Q1_2025_02.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=03/data_Q1_2025_03.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=04/data_Q1_2025_04.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=05/data_Q1_2025_05.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=06/data_Q1_2025_06.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=07/data_Q1_2025_07.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=08/data_Q1_2025_08.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=09/data_Q1_2025_09.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=10/data_Q1_2025_10.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=11/data_Q1_2025_11.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=12/data_Q1_2025_12.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=13/data_Q1_2025_13.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=14/data_Q1_2025_14.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=15/data_Q1_2025_15.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=16/data_Q1_2025_16.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=17/data_Q1_2025_17.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=18/data_Q1_2025_18.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=19/data_Q1_2025_19.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=20/data_Q1_2025_20.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=21/data_Q1_2025_21.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=22/data_Q1_2025_22.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=23/data_Q1_2025_23.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=24/data_Q1_2025_24.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=25/data_Q1_2025_25.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=26/data_Q1_2025_26.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=27/data_Q1_2025_27.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=28/data_Q1_2025_28.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=29/data_Q1_2025_29.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=30/data_Q1_2025_30.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=01/day=31/data_Q1_2025_31.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=01/data_Q1_2025_01.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=02/data_Q1_2025_02.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=03/data_Q1_2025_03.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=04/data_Q1_2025_04.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=05/data_Q1_2025_05.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=06/data_Q1_2025_06.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=07/data_Q1_2025_07.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=08/data_Q1_2025_08.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=09/data_Q1_2025_09.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=10/data_Q1_2025_10.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=11/data_Q1_2025_11.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=12/data_Q1_2025_12.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=13/data_Q1_2025_13.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=14/data_Q1_2025_14.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=15/data_Q1_2025_15.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=16/data_Q1_2025_16.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=17/data_Q1_2025_17.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=18/data_Q1_2025_18.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=19/data_Q1_2025_19.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=20/data_Q1_2025_20.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=21/data_Q1_2025_21.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=22/data_Q1_2025_22.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=23/data_Q1_2025_23.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=24/data_Q1_2025_24.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=25/data_Q1_2025_25.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=26/data_Q1_2025_26.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=27/data_Q1_2025_27.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=02/day=28/data_Q1_2025_28.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=01/data_Q1_2025_01.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=02/data_Q1_2025_02.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=03/data_Q1_2025_03.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=04/data_Q1_2025_04.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=05/data_Q1_2025_05.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=06/data_Q1_2025_06.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=07/data_Q1_2025_07.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=08/data_Q1_2025_08.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=09/data_Q1_2025_09.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=10/data_Q1_2025_10.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=11/data_Q1_2025_11.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=12/data_Q1_2025_12.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=13/data_Q1_2025_13.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=14/data_Q1_2025_14.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=15/data_Q1_2025_15.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=16/data_Q1_2025_16.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=17/data_Q1_2025_17.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=18/data_Q1_2025_18.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=19/data_Q1_2025_19.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=20/data_Q1_2025_20.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=21/data_Q1_2025_21.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=22/data_Q1_2025_22.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=23/data_Q1_2025_23.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=24/data_Q1_2025_24.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=25/data_Q1_2025_25.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=26/data_Q1_2025_26.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=27/data_Q1_2025_27.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=28/data_Q1_2025_28.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=29/data_Q1_2025_29.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=30/data_Q1_2025_30.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=03/day=31/data_Q1_2025_31.parquet\n",
      "Processing: raw/backblaze/zips/data_Q2_2025.zip\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=01/data_Q2_2025_01.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=02/data_Q2_2025_02.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=03/data_Q2_2025_03.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=04/data_Q2_2025_04.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=05/data_Q2_2025_05.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=06/data_Q2_2025_06.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=07/data_Q2_2025_07.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=08/data_Q2_2025_08.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=09/data_Q2_2025_09.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=10/data_Q2_2025_10.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=11/data_Q2_2025_11.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=12/data_Q2_2025_12.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=13/data_Q2_2025_13.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=14/data_Q2_2025_14.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=15/data_Q2_2025_15.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=16/data_Q2_2025_16.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=17/data_Q2_2025_17.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=18/data_Q2_2025_18.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=19/data_Q2_2025_19.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=20/data_Q2_2025_20.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=21/data_Q2_2025_21.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=22/data_Q2_2025_22.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=23/data_Q2_2025_23.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=24/data_Q2_2025_24.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=25/data_Q2_2025_25.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=26/data_Q2_2025_26.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=27/data_Q2_2025_27.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=28/data_Q2_2025_28.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=29/data_Q2_2025_29.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=04/day=30/data_Q2_2025_30.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=01/data_Q2_2025_01.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=02/data_Q2_2025_02.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=03/data_Q2_2025_03.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=04/data_Q2_2025_04.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=05/data_Q2_2025_05.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=06/data_Q2_2025_06.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=07/data_Q2_2025_07.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=08/data_Q2_2025_08.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=09/data_Q2_2025_09.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=10/data_Q2_2025_10.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=11/data_Q2_2025_11.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=12/data_Q2_2025_12.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=13/data_Q2_2025_13.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=14/data_Q2_2025_14.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=15/data_Q2_2025_15.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=16/data_Q2_2025_16.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=17/data_Q2_2025_17.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=18/data_Q2_2025_18.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=19/data_Q2_2025_19.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=20/data_Q2_2025_20.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=21/data_Q2_2025_21.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=22/data_Q2_2025_22.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=23/data_Q2_2025_23.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=24/data_Q2_2025_24.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=25/data_Q2_2025_25.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=26/data_Q2_2025_26.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=27/data_Q2_2025_27.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=28/data_Q2_2025_28.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=29/data_Q2_2025_29.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=30/data_Q2_2025_30.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=05/day=31/data_Q2_2025_31.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=01/data_Q2_2025_01.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=02/data_Q2_2025_02.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=03/data_Q2_2025_03.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=04/data_Q2_2025_04.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=05/data_Q2_2025_05.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=06/data_Q2_2025_06.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=07/data_Q2_2025_07.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=08/data_Q2_2025_08.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=09/data_Q2_2025_09.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=10/data_Q2_2025_10.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=11/data_Q2_2025_11.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=12/data_Q2_2025_12.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=13/data_Q2_2025_13.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=14/data_Q2_2025_14.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=15/data_Q2_2025_15.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=16/data_Q2_2025_16.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=17/data_Q2_2025_17.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=18/data_Q2_2025_18.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=19/data_Q2_2025_19.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=20/data_Q2_2025_20.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=21/data_Q2_2025_21.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=22/data_Q2_2025_22.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=23/data_Q2_2025_23.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=24/data_Q2_2025_24.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=25/data_Q2_2025_25.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=26/data_Q2_2025_26.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=27/data_Q2_2025_27.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=28/data_Q2_2025_28.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=29/data_Q2_2025_29.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=06/day=30/data_Q2_2025_30.parquet\n",
      "Processing: raw/backblaze/zips/data_Q3_2025.zip\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=01/data_Q3_2025_01.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=02/data_Q3_2025_02.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=03/data_Q3_2025_03.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=04/data_Q3_2025_04.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=05/data_Q3_2025_05.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=06/data_Q3_2025_06.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=07/data_Q3_2025_07.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=08/data_Q3_2025_08.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=09/data_Q3_2025_09.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=10/data_Q3_2025_10.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=11/data_Q3_2025_11.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=12/data_Q3_2025_12.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=13/data_Q3_2025_13.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=14/data_Q3_2025_14.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=15/data_Q3_2025_15.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=16/data_Q3_2025_16.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=17/data_Q3_2025_17.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=18/data_Q3_2025_18.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=19/data_Q3_2025_19.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=20/data_Q3_2025_20.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=21/data_Q3_2025_21.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=22/data_Q3_2025_22.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=23/data_Q3_2025_23.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=24/data_Q3_2025_24.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=25/data_Q3_2025_25.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=26/data_Q3_2025_26.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=27/data_Q3_2025_27.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=28/data_Q3_2025_28.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=29/data_Q3_2025_29.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=30/data_Q3_2025_30.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=07/day=31/data_Q3_2025_31.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=01/data_Q3_2025_01.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=02/data_Q3_2025_02.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=03/data_Q3_2025_03.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=04/data_Q3_2025_04.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=05/data_Q3_2025_05.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=06/data_Q3_2025_06.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=07/data_Q3_2025_07.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=08/data_Q3_2025_08.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=09/data_Q3_2025_09.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=10/data_Q3_2025_10.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=11/data_Q3_2025_11.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=12/data_Q3_2025_12.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=13/data_Q3_2025_13.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=14/data_Q3_2025_14.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=15/data_Q3_2025_15.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=16/data_Q3_2025_16.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=17/data_Q3_2025_17.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=18/data_Q3_2025_18.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=19/data_Q3_2025_19.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=20/data_Q3_2025_20.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=21/data_Q3_2025_21.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=22/data_Q3_2025_22.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=23/data_Q3_2025_23.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=24/data_Q3_2025_24.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=25/data_Q3_2025_25.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=26/data_Q3_2025_26.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=27/data_Q3_2025_27.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=28/data_Q3_2025_28.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=29/data_Q3_2025_29.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=30/data_Q3_2025_30.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=08/day=31/data_Q3_2025_31.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=01/data_Q3_2025_01.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=02/data_Q3_2025_02.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=03/data_Q3_2025_03.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=04/data_Q3_2025_04.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=05/data_Q3_2025_05.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=06/data_Q3_2025_06.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=07/data_Q3_2025_07.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=08/data_Q3_2025_08.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=09/data_Q3_2025_09.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=10/data_Q3_2025_10.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=11/data_Q3_2025_11.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=12/data_Q3_2025_12.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=13/data_Q3_2025_13.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=14/data_Q3_2025_14.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=15/data_Q3_2025_15.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=16/data_Q3_2025_16.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=17/data_Q3_2025_17.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=18/data_Q3_2025_18.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=19/data_Q3_2025_19.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=20/data_Q3_2025_20.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=21/data_Q3_2025_21.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=22/data_Q3_2025_22.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=23/data_Q3_2025_23.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=24/data_Q3_2025_24.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=25/data_Q3_2025_25.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=26/data_Q3_2025_26.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=27/data_Q3_2025_27.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=28/data_Q3_2025_28.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=29/data_Q3_2025_29.parquet\n",
      "  Uploaded: curated/backblaze_parquet/year=2025/month=09/day=30/data_Q3_2025_30.parquet\n",
      "Done writing curated partitioned parquet to S3!\n"
     ]
    }
   ],
   "source": [
    "def upload_parquet_to_s3(df, s3_key):\n",
    "    table = pa.Table.from_pandas(df, preserve_index=False)\n",
    "    buf = BytesIO()\n",
    "    pq.write_table(table, buf, compression=\"snappy\")\n",
    "    buf.seek(0)\n",
    "    s3.put_object(Bucket=bucket, Key=s3_key, Body=buf.getvalue())\n",
    "\n",
    "def check_s3_key_exists(s3_key):\n",
    "    try:\n",
    "        s3.head_object(Bucket=bucket, Key=s3_key)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "for zip_key in zip_keys:\n",
    "    print(\"Processing:\", zip_key)\n",
    "    zip_obj = s3.get_object(Bucket=bucket, Key=zip_key)[\"Body\"].read()\n",
    "\n",
    "    with zipfile.ZipFile(BytesIO(zip_obj), \"r\") as z:\n",
    "        # Filter out macOS metadata files (._filename) and only get actual CSV files\n",
    "        csv_files = [n for n in z.namelist() \n",
    "                     if n.endswith(\".csv\") and not os.path.basename(n).startswith(\"._\")]\n",
    "\n",
    "        for csv_name in csv_files:\n",
    "            # csv_name is like 'data_Q1_2024/2024-01-01.csv'\n",
    "            date_str = os.path.basename(csv_name).replace(\".csv\", \"\")\n",
    "            yyyy, mm, dd = date_str.split(\"-\")\n",
    "\n",
    "            # Write to partitioned parquet key\n",
    "            out_key = (\n",
    "                f\"{out_prefix}year={yyyy}/month={mm}/day={dd}/\"\n",
    "                f\"{os.path.basename(zip_key).replace('.zip','')}_{dd}.parquet\"\n",
    "            )\n",
    "\n",
    "            # Check if already extracted\n",
    "            if check_s3_key_exists(out_key):\n",
    "                print(f\"  Skip (already exists): {out_key}\")\n",
    "                continue\n",
    "\n",
    "            with z.open(csv_name) as f:\n",
    "                df = pd.read_csv(f, encoding='utf-8', encoding_errors='replace')\n",
    "\n",
    "            upload_parquet_to_s3(df, out_key)\n",
    "            print(f\"  Uploaded: {out_key}\")\n",
    "\n",
    "print(\"Done writing curated partitioned parquet to S3!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16468ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -q -U datasets pyarrow s3fs pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7465a499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://mlops-backblaze-d7b30cb5-us-east-1/raw/reviews_2023_parquet/raw_review_Electronics/\n",
      "s3://mlops-backblaze-d7b30cb5-us-east-1/raw/reviews_2023_parquet/raw_meta_Electronics/\n"
     ]
    }
   ],
   "source": [
    "HF_DATASET = \"McAuley-Lab/Amazon-Reviews-2023\"\n",
    "\n",
    "REVIEW_CONFIG = \"raw_review_Electronics\"\n",
    "META_CONFIG   = \"raw_meta_Electronics\"\n",
    "\n",
    "s3_reviews_out = f\"s3://{bucket}/raw/reviews_2023_parquet/{REVIEW_CONFIG}/\"\n",
    "s3_meta_out    = f\"s3://{bucket}/raw/reviews_2023_parquet/{META_CONFIG}/\"\n",
    "\n",
    "print(s3_reviews_out)\n",
    "print(s3_meta_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e8eecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Electronics review file...\n",
      "Found: Electronics.jsonl\n",
      "Size: 21568.52 MB\n",
      "\n",
      "Counting total rows in JSONL file...\n",
      "  Counted 500,000 rows...\n",
      "  Counted 1,000,000 rows...\n",
      "  Counted 1,500,000 rows...\n",
      "  Counted 2,000,000 rows...\n",
      "  Counted 2,500,000 rows...\n",
      "  Counted 3,000,000 rows...\n",
      "  Counted 3,500,000 rows...\n",
      "  Counted 4,000,000 rows...\n",
      "  Counted 4,500,000 rows...\n",
      "  Counted 5,000,000 rows...\n",
      "  Counted 5,500,000 rows...\n",
      "  Counted 6,000,000 rows...\n",
      "  Counted 6,500,000 rows...\n",
      "  Counted 7,000,000 rows...\n",
      "  Counted 7,500,000 rows...\n",
      "  Counted 8,000,000 rows...\n",
      "  Counted 8,500,000 rows...\n",
      "  Counted 9,000,000 rows...\n",
      "  Counted 9,500,000 rows...\n",
      "  Counted 10,000,000 rows...\n",
      "  Counted 10,500,000 rows...\n",
      "  Counted 11,000,000 rows...\n",
      "  Counted 11,500,000 rows...\n",
      "  Counted 12,000,000 rows...\n",
      "  Counted 12,500,000 rows...\n",
      "  Counted 13,000,000 rows...\n",
      "  Counted 13,500,000 rows...\n",
      "  Counted 14,000,000 rows...\n",
      "  Counted 14,500,000 rows...\n",
      "  Counted 15,000,000 rows...\n",
      "  Counted 15,500,000 rows...\n",
      "  Counted 16,000,000 rows...\n",
      "  Counted 16,500,000 rows...\n",
      "  Counted 17,000,000 rows...\n",
      "  Counted 17,500,000 rows...\n",
      "  Counted 18,000,000 rows...\n",
      "  Counted 18,500,000 rows...\n",
      "  Counted 19,000,000 rows...\n",
      "  Counted 19,500,000 rows...\n",
      "  Counted 20,000,000 rows...\n",
      "  Counted 20,500,000 rows...\n",
      "  Counted 21,000,000 rows...\n",
      "  Counted 21,500,000 rows...\n",
      "  Counted 22,000,000 rows...\n",
      "  Counted 22,500,000 rows...\n",
      "  Counted 23,000,000 rows...\n",
      "  Counted 23,500,000 rows...\n",
      "  Counted 24,000,000 rows...\n",
      "  Counted 24,500,000 rows...\n",
      "  Counted 25,000,000 rows...\n",
      "  Counted 25,500,000 rows...\n",
      "  Counted 26,000,000 rows...\n",
      "  Counted 26,500,000 rows...\n",
      "  Counted 27,000,000 rows...\n",
      "  Counted 27,500,000 rows...\n",
      "  Counted 28,000,000 rows...\n",
      "  Counted 28,500,000 rows...\n",
      "  Counted 29,000,000 rows...\n",
      "  Counted 29,500,000 rows...\n",
      "  Counted 30,000,000 rows...\n",
      "  Counted 30,500,000 rows...\n",
      "  Counted 31,000,000 rows...\n",
      "  Counted 31,500,000 rows...\n",
      "  Counted 32,000,000 rows...\n",
      "  Counted 32,500,000 rows...\n",
      "  Counted 33,000,000 rows...\n",
      "  Counted 33,500,000 rows...\n",
      "  Counted 34,000,000 rows...\n",
      "  Counted 34,500,000 rows...\n",
      "  Counted 35,000,000 rows...\n",
      "  Counted 35,500,000 rows...\n",
      "  Counted 36,000,000 rows...\n",
      "  Counted 36,500,000 rows...\n",
      "  Counted 37,000,000 rows...\n",
      "  Counted 37,500,000 rows...\n",
      "  Counted 38,000,000 rows...\n",
      "  Counted 38,500,000 rows...\n",
      "  Counted 39,000,000 rows...\n",
      "  Counted 39,500,000 rows...\n",
      "  Counted 40,000,000 rows...\n",
      "  Counted 40,500,000 rows...\n",
      "  Counted 41,000,000 rows...\n",
      "  Counted 41,500,000 rows...\n",
      "  Counted 42,000,000 rows...\n",
      "  Counted 42,500,000 rows...\n",
      "  Counted 43,000,000 rows...\n",
      "  Counted 43,500,000 rows...\n",
      "âœ“ Total rows in JSONL file: 43,886,944\n",
      "\n",
      "Streaming JSONL -> Parquet -> S3 (filtering for hard drive brands)...\n",
      "  Processed 100,000 lines | Filtered: 547/100,000 (0.55%)\n",
      "  Processed 200,000 lines | Filtered: 1,114/200,000 (0.56%)\n",
      "  Processed 300,000 lines | Filtered: 1,578/300,000 (0.53%)\n",
      "  Processed 400,000 lines | Filtered: 2,004/400,000 (0.50%)\n",
      "  Processed 500,000 lines | Filtered: 2,587/500,000 (0.52%)\n",
      "  Processed 600,000 lines | Filtered: 3,096/600,000 (0.52%)\n",
      "  Processed 700,000 lines | Filtered: 3,594/700,000 (0.51%)\n",
      "  Processed 800,000 lines | Filtered: 4,179/800,000 (0.52%)\n",
      "  Processed 900,000 lines | Filtered: 4,670/900,000 (0.52%)\n",
      "  Processed 1,000,000 lines | Filtered: 5,050/1,000,000 (0.51%)\n",
      "  Processed 1,100,000 lines | Filtered: 5,459/1,100,000 (0.50%)\n",
      "  Processed 1,200,000 lines | Filtered: 5,904/1,200,000 (0.49%)\n",
      "  Processed 1,300,000 lines | Filtered: 6,406/1,300,000 (0.49%)\n",
      "  Processed 1,400,000 lines | Filtered: 6,992/1,400,000 (0.50%)\n",
      "  Processed 1,500,000 lines | Filtered: 7,482/1,500,000 (0.50%)\n",
      "  Processed 1,600,000 lines | Filtered: 7,896/1,600,000 (0.49%)\n",
      "  Processed 1,700,000 lines | Filtered: 8,409/1,700,000 (0.49%)\n",
      "  Processed 1,800,000 lines | Filtered: 8,890/1,800,000 (0.49%)\n",
      "  Processed 1,900,000 lines | Filtered: 9,392/1,900,000 (0.49%)\n",
      "  Processed 2,000,000 lines | Filtered: 11,085/2,000,000 (0.55%)\n",
      "  Processed 2,100,000 lines | Filtered: 11,507/2,100,000 (0.55%)\n",
      "  Processed 2,200,000 lines | Filtered: 11,876/2,200,000 (0.54%)\n",
      "  Processed 2,300,000 lines | Filtered: 12,225/2,300,000 (0.53%)\n",
      "  Processed 2,400,000 lines | Filtered: 12,641/2,400,000 (0.53%)\n",
      "  Processed 2,500,000 lines | Filtered: 13,049/2,500,000 (0.52%)\n",
      "  Processed 2,600,000 lines | Filtered: 13,444/2,600,000 (0.52%)\n",
      "  Processed 2,700,000 lines | Filtered: 13,739/2,700,000 (0.51%)\n",
      "  Processed 2,800,000 lines | Filtered: 14,190/2,800,000 (0.51%)\n",
      "  Processed 2,900,000 lines | Filtered: 14,582/2,900,000 (0.50%)\n",
      "  Processed 3,000,000 lines | Filtered: 14,984/3,000,000 (0.50%)\n",
      "  Processed 3,100,000 lines | Filtered: 15,370/3,100,000 (0.50%)\n",
      "  Processed 3,200,000 lines | Filtered: 15,814/3,200,000 (0.49%)\n",
      "  Processed 3,300,000 lines | Filtered: 16,854/3,300,000 (0.51%)\n",
      "  Processed 3,400,000 lines | Filtered: 17,367/3,400,000 (0.51%)\n",
      "  Processed 3,500,000 lines | Filtered: 18,062/3,500,000 (0.52%)\n",
      "  Processed 3,600,000 lines | Filtered: 18,585/3,600,000 (0.52%)\n",
      "  Processed 3,700,000 lines | Filtered: 19,088/3,700,000 (0.52%)\n",
      "  Processed 3,800,000 lines | Filtered: 19,593/3,800,000 (0.52%)\n",
      "  Processed 3,900,000 lines | Filtered: 20,127/3,900,000 (0.52%)\n",
      "  Processed 4,000,000 lines | Filtered: 20,604/4,000,000 (0.52%)\n",
      "  Processed 4,100,000 lines | Filtered: 21,036/4,100,000 (0.51%)\n",
      "  Processed 4,200,000 lines | Filtered: 21,495/4,200,000 (0.51%)\n",
      "  Processed 4,300,000 lines | Filtered: 21,876/4,300,000 (0.51%)\n",
      "  Processed 4,400,000 lines | Filtered: 22,251/4,400,000 (0.51%)\n",
      "  Processed 4,500,000 lines | Filtered: 22,680/4,500,000 (0.50%)\n",
      "  Processed 4,600,000 lines | Filtered: 22,949/4,600,000 (0.50%)\n",
      "  Processed 4,700,000 lines | Filtered: 23,421/4,700,000 (0.50%)\n",
      "  Processed 4,800,000 lines | Filtered: 23,814/4,800,000 (0.50%)\n",
      "  Processed 4,900,000 lines | Filtered: 24,199/4,900,000 (0.49%)\n",
      "  Processed 5,000,000 lines | Filtered: 24,607/5,000,000 (0.49%)\n",
      "  Processed 5,100,000 lines | Filtered: 25,088/5,100,000 (0.49%)\n",
      "  Processed 5,200,000 lines | Filtered: 25,446/5,200,000 (0.49%)\n",
      "  Processed 5,300,000 lines | Filtered: 26,020/5,300,000 (0.49%)\n",
      "  Processed 5,400,000 lines | Filtered: 26,423/5,400,000 (0.49%)\n",
      "  Processed 5,500,000 lines | Filtered: 26,888/5,500,000 (0.49%)\n",
      "  Processed 5,600,000 lines | Filtered: 27,376/5,600,000 (0.49%)\n",
      "  Processed 5,700,000 lines | Filtered: 27,843/5,700,000 (0.49%)\n",
      "  Processed 5,800,000 lines | Filtered: 28,300/5,800,000 (0.49%)\n",
      "  Processed 5,900,000 lines | Filtered: 28,697/5,900,000 (0.49%)\n",
      "  Processed 6,000,000 lines | Filtered: 29,118/6,000,000 (0.49%)\n",
      "  Processed 6,100,000 lines | Filtered: 29,687/6,100,000 (0.49%)\n",
      "  Processed 6,200,000 lines | Filtered: 30,085/6,200,000 (0.49%)\n",
      "  Processed 6,300,000 lines | Filtered: 30,499/6,300,000 (0.48%)\n",
      "  Processed 6,400,000 lines | Filtered: 30,858/6,400,000 (0.48%)\n",
      "  Processed 6,500,000 lines | Filtered: 31,396/6,500,000 (0.48%)\n",
      "  Processed 6,600,000 lines | Filtered: 31,678/6,600,000 (0.48%)\n",
      "  Processed 6,700,000 lines | Filtered: 32,236/6,700,000 (0.48%)\n",
      "  Processed 6,800,000 lines | Filtered: 32,790/6,800,000 (0.48%)\n",
      "  Processed 6,900,000 lines | Filtered: 33,371/6,900,000 (0.48%)\n",
      "  Processed 7,000,000 lines | Filtered: 33,954/7,000,000 (0.49%)\n",
      "  Processed 7,100,000 lines | Filtered: 34,417/7,100,000 (0.48%)\n",
      "  Processed 7,200,000 lines | Filtered: 34,923/7,200,000 (0.49%)\n",
      "  Processed 7,300,000 lines | Filtered: 35,290/7,300,000 (0.48%)\n",
      "  Processed 7,400,000 lines | Filtered: 35,696/7,400,000 (0.48%)\n",
      "  Processed 7,500,000 lines | Filtered: 36,147/7,500,000 (0.48%)\n",
      "  Processed 7,600,000 lines | Filtered: 36,548/7,600,000 (0.48%)\n",
      "  Processed 7,700,000 lines | Filtered: 37,166/7,700,000 (0.48%)\n",
      "  Processed 7,800,000 lines | Filtered: 37,710/7,800,000 (0.48%)\n",
      "  Processed 7,900,000 lines | Filtered: 38,327/7,900,000 (0.49%)\n",
      "  Processed 8,000,000 lines | Filtered: 38,759/8,000,000 (0.48%)\n",
      "  Processed 8,100,000 lines | Filtered: 39,141/8,100,000 (0.48%)\n",
      "  Processed 8,200,000 lines | Filtered: 39,477/8,200,000 (0.48%)\n",
      "  Processed 8,300,000 lines | Filtered: 39,859/8,300,000 (0.48%)\n",
      "  Processed 8,400,000 lines | Filtered: 40,264/8,400,000 (0.48%)\n",
      "  Processed 8,500,000 lines | Filtered: 40,666/8,500,000 (0.48%)\n",
      "  Processed 8,600,000 lines | Filtered: 41,148/8,600,000 (0.48%)\n",
      "  Processed 8,700,000 lines | Filtered: 42,109/8,700,000 (0.48%)\n",
      "  Processed 8,800,000 lines | Filtered: 42,509/8,800,000 (0.48%)\n",
      "  Processed 8,900,000 lines | Filtered: 42,884/8,900,000 (0.48%)\n",
      "  Processed 9,000,000 lines | Filtered: 43,247/9,000,000 (0.48%)\n",
      "  Processed 9,100,000 lines | Filtered: 43,646/9,100,000 (0.48%)\n",
      "  Processed 9,200,000 lines | Filtered: 43,971/9,200,000 (0.48%)\n",
      "  Processed 9,300,000 lines | Filtered: 44,299/9,300,000 (0.48%)\n",
      "  Processed 9,400,000 lines | Filtered: 44,646/9,400,000 (0.47%)\n",
      "  Processed 9,500,000 lines | Filtered: 45,054/9,500,000 (0.47%)\n",
      "  Processed 9,600,000 lines | Filtered: 45,403/9,600,000 (0.47%)\n",
      "  Processed 9,700,000 lines | Filtered: 45,813/9,700,000 (0.47%)\n",
      "  Processed 9,800,000 lines | Filtered: 46,164/9,800,000 (0.47%)\n",
      "  Processed 9,900,000 lines | Filtered: 46,514/9,900,000 (0.47%)\n",
      "  Processed 10,000,000 lines | Filtered: 46,857/10,000,000 (0.47%)\n",
      "  Processed 10,100,000 lines | Filtered: 47,218/10,100,000 (0.47%)\n",
      "  Processed 10,200,000 lines | Filtered: 47,557/10,200,000 (0.47%)\n",
      "  Processed 10,300,000 lines | Filtered: 47,975/10,300,000 (0.47%)\n",
      "  Processed 10,400,000 lines | Filtered: 48,462/10,400,000 (0.47%)\n",
      "  Processed 10,500,000 lines | Filtered: 48,822/10,500,000 (0.46%)\n",
      "  Processed 10,600,000 lines | Filtered: 49,248/10,600,000 (0.46%)\n",
      "  Processed 10,700,000 lines | Filtered: 49,874/10,700,000 (0.47%)\n",
      "  Processed 10,800,000 lines | Filtered: 50,267/10,800,000 (0.47%)\n",
      "  Processed 10,900,000 lines | Filtered: 50,738/10,900,000 (0.47%)\n",
      "  Processed 11,000,000 lines | Filtered: 51,169/11,000,000 (0.47%)\n",
      "  Processed 11,100,000 lines | Filtered: 51,535/11,100,000 (0.46%)\n",
      "  Processed 11,200,000 lines | Filtered: 51,970/11,200,000 (0.46%)\n",
      "  Processed 11,300,000 lines | Filtered: 52,467/11,300,000 (0.46%)\n",
      "  Processed 11,400,000 lines | Filtered: 52,830/11,400,000 (0.46%)\n",
      "  Processed 11,500,000 lines | Filtered: 53,153/11,500,000 (0.46%)\n",
      "  Processed 11,600,000 lines | Filtered: 53,579/11,600,000 (0.46%)\n",
      "  Processed 11,700,000 lines | Filtered: 53,969/11,700,000 (0.46%)\n",
      "  Processed 11,800,000 lines | Filtered: 54,307/11,800,000 (0.46%)\n",
      "  Processed 11,900,000 lines | Filtered: 54,846/11,900,000 (0.46%)\n",
      "  Processed 12,000,000 lines | Filtered: 55,217/12,000,000 (0.46%)\n",
      "  Processed 12,100,000 lines | Filtered: 55,599/12,100,000 (0.46%)\n",
      "  Processed 12,200,000 lines | Filtered: 56,013/12,200,000 (0.46%)\n",
      "  Processed 12,300,000 lines | Filtered: 56,432/12,300,000 (0.46%)\n",
      "  Processed 12,400,000 lines | Filtered: 56,813/12,400,000 (0.46%)\n",
      "  Processed 12,500,000 lines | Filtered: 57,210/12,500,000 (0.46%)\n",
      "  Processed 12,600,000 lines | Filtered: 57,635/12,600,000 (0.46%)\n",
      "  Processed 12,700,000 lines | Filtered: 58,044/12,700,000 (0.46%)\n",
      "  Processed 12,800,000 lines | Filtered: 58,618/12,800,000 (0.46%)\n",
      "  Processed 12,900,000 lines | Filtered: 59,159/12,900,000 (0.46%)\n",
      "  Processed 13,000,000 lines | Filtered: 59,822/13,000,000 (0.46%)\n",
      "  Processed 13,100,000 lines | Filtered: 60,266/13,100,000 (0.46%)\n",
      "  Processed 13,200,000 lines | Filtered: 60,712/13,200,000 (0.46%)\n",
      "  Processed 13,300,000 lines | Filtered: 61,305/13,300,000 (0.46%)\n",
      "  Processed 13,400,000 lines | Filtered: 61,774/13,400,000 (0.46%)\n",
      "  Processed 13,500,000 lines | Filtered: 62,228/13,500,000 (0.46%)\n",
      "  Processed 13,600,000 lines | Filtered: 62,705/13,600,000 (0.46%)\n",
      "  Processed 13,700,000 lines | Filtered: 63,097/13,700,000 (0.46%)\n",
      "  Processed 13,800,000 lines | Filtered: 63,462/13,800,000 (0.46%)\n",
      "  Processed 13,900,000 lines | Filtered: 63,882/13,900,000 (0.46%)\n",
      "  Processed 14,000,000 lines | Filtered: 64,263/14,000,000 (0.46%)\n",
      "  Processed 14,100,000 lines | Filtered: 64,688/14,100,000 (0.46%)\n",
      "  Processed 14,200,000 lines | Filtered: 65,160/14,200,000 (0.46%)\n",
      "  Processed 14,300,000 lines | Filtered: 65,559/14,300,000 (0.46%)\n",
      "  Processed 14,400,000 lines | Filtered: 66,078/14,400,000 (0.46%)\n",
      "  Processed 14,500,000 lines | Filtered: 66,509/14,500,000 (0.46%)\n",
      "  Processed 14,600,000 lines | Filtered: 66,898/14,600,000 (0.46%)\n",
      "  Processed 14,700,000 lines | Filtered: 67,192/14,700,000 (0.46%)\n",
      "  Processed 14,800,000 lines | Filtered: 67,467/14,800,000 (0.46%)\n",
      "  Processed 14,900,000 lines | Filtered: 67,725/14,900,000 (0.45%)\n",
      "  Processed 15,000,000 lines | Filtered: 68,055/15,000,000 (0.45%)\n",
      "  Processed 15,100,000 lines | Filtered: 68,396/15,100,000 (0.45%)\n",
      "  Processed 15,200,000 lines | Filtered: 68,749/15,200,000 (0.45%)\n",
      "  Processed 15,300,000 lines | Filtered: 69,065/15,300,000 (0.45%)\n",
      "  Processed 15,400,000 lines | Filtered: 69,425/15,400,000 (0.45%)\n",
      "  Processed 15,500,000 lines | Filtered: 69,797/15,500,000 (0.45%)\n",
      "  Processed 15,600,000 lines | Filtered: 70,217/15,600,000 (0.45%)\n",
      "  Processed 15,700,000 lines | Filtered: 70,786/15,700,000 (0.45%)\n",
      "  Processed 15,800,000 lines | Filtered: 71,285/15,800,000 (0.45%)\n",
      "  Processed 15,900,000 lines | Filtered: 71,605/15,900,000 (0.45%)\n",
      "  Processed 16,000,000 lines | Filtered: 71,902/16,000,000 (0.45%)\n",
      "  Processed 16,100,000 lines | Filtered: 72,135/16,100,000 (0.45%)\n",
      "  Processed 16,200,000 lines | Filtered: 72,591/16,200,000 (0.45%)\n",
      "  Processed 16,300,000 lines | Filtered: 73,020/16,300,000 (0.45%)\n",
      "  Processed 16,400,000 lines | Filtered: 73,454/16,400,000 (0.45%)\n",
      "  Processed 16,500,000 lines | Filtered: 73,878/16,500,000 (0.45%)\n",
      "  Processed 16,600,000 lines | Filtered: 74,286/16,600,000 (0.45%)\n",
      "  Processed 16,700,000 lines | Filtered: 74,625/16,700,000 (0.45%)\n",
      "  Processed 16,800,000 lines | Filtered: 74,998/16,800,000 (0.45%)\n",
      "  Processed 16,900,000 lines | Filtered: 75,251/16,900,000 (0.45%)\n",
      "  Processed 17,000,000 lines | Filtered: 75,480/17,000,000 (0.44%)\n",
      "  Processed 17,100,000 lines | Filtered: 75,746/17,100,000 (0.44%)\n",
      "  Processed 17,200,000 lines | Filtered: 76,028/17,200,000 (0.44%)\n",
      "  Processed 17,300,000 lines | Filtered: 76,427/17,300,000 (0.44%)\n",
      "  Processed 17,400,000 lines | Filtered: 76,742/17,400,000 (0.44%)\n",
      "  Processed 17,500,000 lines | Filtered: 77,041/17,500,000 (0.44%)\n",
      "  Processed 17,600,000 lines | Filtered: 77,401/17,600,000 (0.44%)\n",
      "  Processed 17,700,000 lines | Filtered: 77,661/17,700,000 (0.44%)\n",
      "  Processed 17,800,000 lines | Filtered: 78,089/17,800,000 (0.44%)\n",
      "  Processed 17,900,000 lines | Filtered: 78,395/17,900,000 (0.44%)\n",
      "  Processed 18,000,000 lines | Filtered: 78,824/18,000,000 (0.44%)\n",
      "  Processed 18,100,000 lines | Filtered: 79,264/18,100,000 (0.44%)\n",
      "  Processed 18,200,000 lines | Filtered: 79,580/18,200,000 (0.44%)\n",
      "  Processed 18,300,000 lines | Filtered: 79,960/18,300,000 (0.44%)\n",
      "  Processed 18,400,000 lines | Filtered: 80,303/18,400,000 (0.44%)\n",
      "  Processed 18,500,000 lines | Filtered: 80,602/18,500,000 (0.44%)\n",
      "  Processed 18,600,000 lines | Filtered: 80,899/18,600,000 (0.43%)\n",
      "  Processed 18,700,000 lines | Filtered: 81,313/18,700,000 (0.43%)\n",
      "  Processed 18,800,000 lines | Filtered: 81,630/18,800,000 (0.43%)\n",
      "  Processed 18,900,000 lines | Filtered: 82,111/18,900,000 (0.43%)\n",
      "  Processed 19,000,000 lines | Filtered: 82,694/19,000,000 (0.44%)\n",
      "  Processed 19,100,000 lines | Filtered: 83,147/19,100,000 (0.44%)\n",
      "  Processed 19,200,000 lines | Filtered: 83,433/19,200,000 (0.43%)\n",
      "  Processed 19,300,000 lines | Filtered: 83,737/19,300,000 (0.43%)\n",
      "  Processed 19,400,000 lines | Filtered: 84,113/19,400,000 (0.43%)\n",
      "  Processed 19,500,000 lines | Filtered: 84,466/19,500,000 (0.43%)\n",
      "  Processed 19,600,000 lines | Filtered: 84,789/19,600,000 (0.43%)\n",
      "  Processed 19,700,000 lines | Filtered: 85,384/19,700,000 (0.43%)\n",
      "  Processed 19,800,000 lines | Filtered: 85,851/19,800,000 (0.43%)\n",
      "  Processed 19,900,000 lines | Filtered: 86,189/19,900,000 (0.43%)\n",
      "  Processed 20,000,000 lines | Filtered: 86,546/20,000,000 (0.43%)\n",
      "  Processed 20,100,000 lines | Filtered: 87,010/20,100,000 (0.43%)\n",
      "  Processed 20,200,000 lines | Filtered: 87,337/20,200,000 (0.43%)\n",
      "  Processed 20,300,000 lines | Filtered: 87,872/20,300,000 (0.43%)\n",
      "  Processed 20,400,000 lines | Filtered: 88,251/20,400,000 (0.43%)\n",
      "  Processed 20,500,000 lines | Filtered: 88,650/20,500,000 (0.43%)\n",
      "  Processed 20,600,000 lines | Filtered: 89,120/20,600,000 (0.43%)\n",
      "  Processed 20,700,000 lines | Filtered: 89,457/20,700,000 (0.43%)\n",
      "  Processed 20,800,000 lines | Filtered: 89,808/20,800,000 (0.43%)\n",
      "  Processed 20,900,000 lines | Filtered: 90,247/20,900,000 (0.43%)\n",
      "  Processed 21,000,000 lines | Filtered: 90,555/21,000,000 (0.43%)\n",
      "  Processed 21,100,000 lines | Filtered: 90,868/21,100,000 (0.43%)\n",
      "  Processed 21,200,000 lines | Filtered: 91,203/21,200,000 (0.43%)\n",
      "  Processed 21,300,000 lines | Filtered: 91,548/21,300,000 (0.43%)\n",
      "  Processed 21,400,000 lines | Filtered: 91,920/21,400,000 (0.43%)\n",
      "  Processed 21,500,000 lines | Filtered: 92,374/21,500,000 (0.43%)\n",
      "  Processed 21,600,000 lines | Filtered: 92,754/21,600,000 (0.43%)\n",
      "  Processed 21,700,000 lines | Filtered: 93,024/21,700,000 (0.43%)\n",
      "  Processed 21,800,000 lines | Filtered: 93,444/21,800,000 (0.43%)\n",
      "  Processed 21,900,000 lines | Filtered: 93,949/21,900,000 (0.43%)\n",
      "  Processed 22,000,000 lines | Filtered: 94,316/22,000,000 (0.43%)\n",
      "  Processed 22,100,000 lines | Filtered: 94,703/22,100,000 (0.43%)\n",
      "  Processed 22,200,000 lines | Filtered: 95,087/22,200,000 (0.43%)\n",
      "  Processed 22,300,000 lines | Filtered: 95,487/22,300,000 (0.43%)\n",
      "  Processed 22,400,000 lines | Filtered: 95,823/22,400,000 (0.43%)\n",
      "  Processed 22,500,000 lines | Filtered: 96,160/22,500,000 (0.43%)\n",
      "  Processed 22,600,000 lines | Filtered: 96,535/22,600,000 (0.43%)\n",
      "  Processed 22,700,000 lines | Filtered: 96,935/22,700,000 (0.43%)\n",
      "  Processed 22,800,000 lines | Filtered: 97,280/22,800,000 (0.43%)\n",
      "  Processed 22,900,000 lines | Filtered: 98,258/22,900,000 (0.43%)\n",
      "  Processed 23,000,000 lines | Filtered: 98,573/23,000,000 (0.43%)\n",
      "  Processed 23,100,000 lines | Filtered: 98,959/23,100,000 (0.43%)\n",
      "  Processed 23,200,000 lines | Filtered: 99,238/23,200,000 (0.43%)\n",
      "  Processed 23,300,000 lines | Filtered: 99,552/23,300,000 (0.43%)\n",
      "  Processed 23,400,000 lines | Filtered: 99,958/23,400,000 (0.43%)\n",
      "  Processed 23,500,000 lines | Filtered: 100,523/23,500,000 (0.43%)\n",
      "  Processed 23,600,000 lines | Filtered: 100,904/23,600,000 (0.43%)\n",
      "  Processed 23,700,000 lines | Filtered: 101,258/23,700,000 (0.43%)\n",
      "  Processed 23,800,000 lines | Filtered: 101,641/23,800,000 (0.43%)\n",
      "  Processed 23,900,000 lines | Filtered: 101,967/23,900,000 (0.43%)\n",
      "  Processed 24,000,000 lines | Filtered: 102,344/24,000,000 (0.43%)\n",
      "  Processed 24,100,000 lines | Filtered: 102,878/24,100,000 (0.43%)\n",
      "  Processed 24,200,000 lines | Filtered: 103,286/24,200,000 (0.43%)\n",
      "  Processed 24,300,000 lines | Filtered: 103,580/24,300,000 (0.43%)\n",
      "  Processed 24,400,000 lines | Filtered: 103,962/24,400,000 (0.43%)\n",
      "  Processed 24,500,000 lines | Filtered: 104,251/24,500,000 (0.43%)\n",
      "  Processed 24,600,000 lines | Filtered: 104,599/24,600,000 (0.43%)\n",
      "  Processed 24,700,000 lines | Filtered: 104,886/24,700,000 (0.42%)\n",
      "  Processed 24,800,000 lines | Filtered: 105,253/24,800,000 (0.42%)\n",
      "  Processed 24,900,000 lines | Filtered: 105,611/24,900,000 (0.42%)\n",
      "  Processed 25,000,000 lines | Filtered: 106,000/25,000,000 (0.42%)\n",
      "  Processed 25,100,000 lines | Filtered: 106,399/25,100,000 (0.42%)\n",
      "  Processed 25,200,000 lines | Filtered: 106,890/25,200,000 (0.42%)\n",
      "  Processed 25,300,000 lines | Filtered: 107,181/25,300,000 (0.42%)\n",
      "  Processed 25,400,000 lines | Filtered: 107,532/25,400,000 (0.42%)\n",
      "  Processed 25,500,000 lines | Filtered: 107,958/25,500,000 (0.42%)\n",
      "  Processed 25,600,000 lines | Filtered: 108,826/25,600,000 (0.43%)\n",
      "  Processed 25,700,000 lines | Filtered: 109,739/25,700,000 (0.43%)\n",
      "  Processed 25,800,000 lines | Filtered: 110,022/25,800,000 (0.43%)\n",
      "  Processed 25,900,000 lines | Filtered: 110,266/25,900,000 (0.43%)\n",
      "  Processed 26,000,000 lines | Filtered: 110,593/26,000,000 (0.43%)\n",
      "  Processed 26,100,000 lines | Filtered: 111,012/26,100,000 (0.43%)\n",
      "  Processed 26,200,000 lines | Filtered: 111,433/26,200,000 (0.43%)\n",
      "  Processed 26,300,000 lines | Filtered: 111,795/26,300,000 (0.43%)\n",
      "  Processed 26,400,000 lines | Filtered: 112,079/26,400,000 (0.42%)\n",
      "  Processed 26,500,000 lines | Filtered: 112,584/26,500,000 (0.42%)\n",
      "  Processed 26,600,000 lines | Filtered: 112,927/26,600,000 (0.42%)\n",
      "  Processed 26,700,000 lines | Filtered: 113,272/26,700,000 (0.42%)\n",
      "  Processed 26,800,000 lines | Filtered: 114,697/26,800,000 (0.43%)\n",
      "  Processed 26,900,000 lines | Filtered: 115,005/26,900,000 (0.43%)\n",
      "  Processed 27,000,000 lines | Filtered: 115,349/27,000,000 (0.43%)\n",
      "  Processed 27,100,000 lines | Filtered: 115,931/27,100,000 (0.43%)\n",
      "  Processed 27,200,000 lines | Filtered: 116,231/27,200,000 (0.43%)\n",
      "  Processed 27,300,000 lines | Filtered: 116,559/27,300,000 (0.43%)\n",
      "  Processed 27,400,000 lines | Filtered: 116,926/27,400,000 (0.43%)\n",
      "  Processed 27,500,000 lines | Filtered: 117,266/27,500,000 (0.43%)\n",
      "  Processed 27,600,000 lines | Filtered: 117,598/27,600,000 (0.43%)\n",
      "  Processed 27,700,000 lines | Filtered: 117,962/27,700,000 (0.43%)\n",
      "  Processed 27,800,000 lines | Filtered: 118,330/27,800,000 (0.43%)\n",
      "  Processed 27,900,000 lines | Filtered: 118,657/27,900,000 (0.43%)\n",
      "  Processed 28,000,000 lines | Filtered: 118,946/28,000,000 (0.42%)\n",
      "  Processed 28,100,000 lines | Filtered: 119,254/28,100,000 (0.42%)\n",
      "  Processed 28,200,000 lines | Filtered: 119,472/28,200,000 (0.42%)\n",
      "  Processed 28,300,000 lines | Filtered: 119,798/28,300,000 (0.42%)\n",
      "  Processed 28,400,000 lines | Filtered: 120,156/28,400,000 (0.42%)\n",
      "  Processed 28,500,000 lines | Filtered: 120,496/28,500,000 (0.42%)\n",
      "  Processed 28,600,000 lines | Filtered: 120,878/28,600,000 (0.42%)\n",
      "  Processed 28,700,000 lines | Filtered: 121,468/28,700,000 (0.42%)\n",
      "  Processed 28,800,000 lines | Filtered: 121,831/28,800,000 (0.42%)\n",
      "  Processed 28,900,000 lines | Filtered: 122,134/28,900,000 (0.42%)\n",
      "  Processed 29,000,000 lines | Filtered: 122,404/29,000,000 (0.42%)\n",
      "  Processed 29,100,000 lines | Filtered: 122,683/29,100,000 (0.42%)\n",
      "  Processed 29,200,000 lines | Filtered: 122,988/29,200,000 (0.42%)\n",
      "  Processed 29,300,000 lines | Filtered: 123,390/29,300,000 (0.42%)\n",
      "  Processed 29,400,000 lines | Filtered: 123,713/29,400,000 (0.42%)\n",
      "  Processed 29,500,000 lines | Filtered: 124,100/29,500,000 (0.42%)\n",
      "  Processed 29,600,000 lines | Filtered: 124,404/29,600,000 (0.42%)\n",
      "  Processed 29,700,000 lines | Filtered: 125,014/29,700,000 (0.42%)\n",
      "  Processed 29,800,000 lines | Filtered: 125,392/29,800,000 (0.42%)\n",
      "  Processed 29,900,000 lines | Filtered: 125,841/29,900,000 (0.42%)\n",
      "  Processed 30,000,000 lines | Filtered: 126,135/30,000,000 (0.42%)\n",
      "  Processed 30,100,000 lines | Filtered: 126,746/30,100,000 (0.42%)\n",
      "  Processed 30,200,000 lines | Filtered: 127,197/30,200,000 (0.42%)\n",
      "  Processed 30,300,000 lines | Filtered: 127,508/30,300,000 (0.42%)\n",
      "  Processed 30,400,000 lines | Filtered: 127,756/30,400,000 (0.42%)\n",
      "  Processed 30,500,000 lines | Filtered: 128,040/30,500,000 (0.42%)\n",
      "  Processed 30,600,000 lines | Filtered: 128,439/30,600,000 (0.42%)\n",
      "  Processed 30,700,000 lines | Filtered: 128,723/30,700,000 (0.42%)\n",
      "  Processed 30,800,000 lines | Filtered: 129,106/30,800,000 (0.42%)\n",
      "  Processed 30,900,000 lines | Filtered: 129,453/30,900,000 (0.42%)\n",
      "  Processed 31,000,000 lines | Filtered: 129,712/31,000,000 (0.42%)\n",
      "  Processed 31,100,000 lines | Filtered: 130,091/31,100,000 (0.42%)\n",
      "  Processed 31,200,000 lines | Filtered: 130,383/31,200,000 (0.42%)\n",
      "  Processed 31,300,000 lines | Filtered: 131,255/31,300,000 (0.42%)\n",
      "  Processed 31,400,000 lines | Filtered: 131,572/31,400,000 (0.42%)\n",
      "  Processed 31,500,000 lines | Filtered: 131,862/31,500,000 (0.42%)\n",
      "  Processed 31,600,000 lines | Filtered: 132,176/31,600,000 (0.42%)\n",
      "  Processed 31,700,000 lines | Filtered: 132,486/31,700,000 (0.42%)\n",
      "  Processed 31,800,000 lines | Filtered: 132,753/31,800,000 (0.42%)\n",
      "  Processed 31,900,000 lines | Filtered: 133,154/31,900,000 (0.42%)\n",
      "  Processed 32,000,000 lines | Filtered: 133,581/32,000,000 (0.42%)\n",
      "  Processed 32,100,000 lines | Filtered: 134,202/32,100,000 (0.42%)\n",
      "  Processed 32,200,000 lines | Filtered: 134,469/32,200,000 (0.42%)\n",
      "  Processed 32,300,000 lines | Filtered: 134,744/32,300,000 (0.42%)\n",
      "  Processed 32,400,000 lines | Filtered: 135,065/32,400,000 (0.42%)\n",
      "  Processed 32,500,000 lines | Filtered: 135,796/32,500,000 (0.42%)\n",
      "  Processed 32,600,000 lines | Filtered: 136,055/32,600,000 (0.42%)\n",
      "  Processed 32,700,000 lines | Filtered: 136,566/32,700,000 (0.42%)\n",
      "  Processed 32,800,000 lines | Filtered: 136,882/32,800,000 (0.42%)\n",
      "  Processed 32,900,000 lines | Filtered: 137,234/32,900,000 (0.42%)\n",
      "  Processed 33,000,000 lines | Filtered: 137,499/33,000,000 (0.42%)\n",
      "  Processed 33,100,000 lines | Filtered: 137,765/33,100,000 (0.42%)\n",
      "  Processed 33,200,000 lines | Filtered: 138,042/33,200,000 (0.42%)\n",
      "  Processed 33,300,000 lines | Filtered: 138,499/33,300,000 (0.42%)\n",
      "  Processed 33,400,000 lines | Filtered: 138,740/33,400,000 (0.42%)\n",
      "  Processed 33,500,000 lines | Filtered: 139,090/33,500,000 (0.42%)\n",
      "  Processed 33,600,000 lines | Filtered: 139,339/33,600,000 (0.41%)\n",
      "  Processed 33,700,000 lines | Filtered: 139,584/33,700,000 (0.41%)\n",
      "  Processed 33,800,000 lines | Filtered: 139,869/33,800,000 (0.41%)\n",
      "  Processed 33,900,000 lines | Filtered: 140,218/33,900,000 (0.41%)\n",
      "  Processed 34,000,000 lines | Filtered: 140,498/34,000,000 (0.41%)\n",
      "  Processed 34,100,000 lines | Filtered: 140,791/34,100,000 (0.41%)\n",
      "  Processed 34,200,000 lines | Filtered: 141,143/34,200,000 (0.41%)\n",
      "  Processed 34,300,000 lines | Filtered: 141,425/34,300,000 (0.41%)\n",
      "  Processed 34,400,000 lines | Filtered: 142,069/34,400,000 (0.41%)\n",
      "  Processed 34,500,000 lines | Filtered: 142,474/34,500,000 (0.41%)\n",
      "  Processed 34,600,000 lines | Filtered: 142,775/34,600,000 (0.41%)\n",
      "  Processed 34,700,000 lines | Filtered: 143,144/34,700,000 (0.41%)\n",
      "  Processed 34,800,000 lines | Filtered: 143,408/34,800,000 (0.41%)\n",
      "  Processed 34,900,000 lines | Filtered: 143,765/34,900,000 (0.41%)\n",
      "  Processed 35,000,000 lines | Filtered: 144,203/35,000,000 (0.41%)\n",
      "  Processed 35,100,000 lines | Filtered: 144,532/35,100,000 (0.41%)\n",
      "  Processed 35,200,000 lines | Filtered: 144,940/35,200,000 (0.41%)\n",
      "  Processed 35,300,000 lines | Filtered: 145,452/35,300,000 (0.41%)\n",
      "  Processed 35,400,000 lines | Filtered: 145,768/35,400,000 (0.41%)\n",
      "  Processed 35,500,000 lines | Filtered: 146,081/35,500,000 (0.41%)\n",
      "  Processed 35,600,000 lines | Filtered: 146,407/35,600,000 (0.41%)\n",
      "  Processed 35,700,000 lines | Filtered: 146,703/35,700,000 (0.41%)\n",
      "  Processed 35,800,000 lines | Filtered: 147,194/35,800,000 (0.41%)\n",
      "  Processed 35,900,000 lines | Filtered: 147,558/35,900,000 (0.41%)\n",
      "  Processed 36,000,000 lines | Filtered: 147,948/36,000,000 (0.41%)\n",
      "  Processed 36,100,000 lines | Filtered: 148,450/36,100,000 (0.41%)\n",
      "  Processed 36,200,000 lines | Filtered: 148,850/36,200,000 (0.41%)\n",
      "  Processed 36,300,000 lines | Filtered: 149,194/36,300,000 (0.41%)\n",
      "  Processed 36,400,000 lines | Filtered: 149,454/36,400,000 (0.41%)\n",
      "  Processed 36,500,000 lines | Filtered: 149,851/36,500,000 (0.41%)\n",
      "  Processed 36,600,000 lines | Filtered: 150,198/36,600,000 (0.41%)\n",
      "  Processed 36,700,000 lines | Filtered: 150,554/36,700,000 (0.41%)\n",
      "  Processed 36,800,000 lines | Filtered: 150,864/36,800,000 (0.41%)\n",
      "  Processed 36,900,000 lines | Filtered: 151,262/36,900,000 (0.41%)\n",
      "  Processed 37,000,000 lines | Filtered: 151,583/37,000,000 (0.41%)\n",
      "  Processed 37,100,000 lines | Filtered: 151,951/37,100,000 (0.41%)\n",
      "  Processed 37,200,000 lines | Filtered: 152,205/37,200,000 (0.41%)\n",
      "  Processed 37,300,000 lines | Filtered: 152,947/37,300,000 (0.41%)\n",
      "  Processed 37,400,000 lines | Filtered: 153,182/37,400,000 (0.41%)\n",
      "  Processed 37,500,000 lines | Filtered: 153,606/37,500,000 (0.41%)\n",
      "  Processed 37,600,000 lines | Filtered: 153,866/37,600,000 (0.41%)\n",
      "  Processed 37,700,000 lines | Filtered: 154,212/37,700,000 (0.41%)\n",
      "  Processed 37,800,000 lines | Filtered: 154,423/37,800,000 (0.41%)\n",
      "  Processed 37,900,000 lines | Filtered: 154,740/37,900,000 (0.41%)\n",
      "  Processed 38,000,000 lines | Filtered: 155,109/38,000,000 (0.41%)\n",
      "  Processed 38,100,000 lines | Filtered: 155,342/38,100,000 (0.41%)\n",
      "  Processed 38,200,000 lines | Filtered: 155,547/38,200,000 (0.41%)\n",
      "  Processed 38,300,000 lines | Filtered: 155,795/38,300,000 (0.41%)\n",
      "  Processed 38,400,000 lines | Filtered: 156,229/38,400,000 (0.41%)\n",
      "  Processed 38,500,000 lines | Filtered: 156,474/38,500,000 (0.41%)\n",
      "  Processed 38,600,000 lines | Filtered: 156,675/38,600,000 (0.41%)\n",
      "  Processed 38,700,000 lines | Filtered: 156,917/38,700,000 (0.41%)\n",
      "  Processed 38,800,000 lines | Filtered: 157,210/38,800,000 (0.41%)\n",
      "  Processed 38,900,000 lines | Filtered: 157,555/38,900,000 (0.41%)\n",
      "  Processed 39,000,000 lines | Filtered: 157,817/39,000,000 (0.40%)\n",
      "  Processed 39,100,000 lines | Filtered: 158,056/39,100,000 (0.40%)\n",
      "  Processed 39,200,000 lines | Filtered: 158,291/39,200,000 (0.40%)\n",
      "  Processed 39,300,000 lines | Filtered: 158,639/39,300,000 (0.40%)\n",
      "  Processed 39,400,000 lines | Filtered: 159,196/39,400,000 (0.40%)\n",
      "  Processed 39,500,000 lines | Filtered: 159,473/39,500,000 (0.40%)\n",
      "  Processed 39,600,000 lines | Filtered: 159,807/39,600,000 (0.40%)\n",
      "  Processed 39,700,000 lines | Filtered: 160,115/39,700,000 (0.40%)\n",
      "  Processed 39,800,000 lines | Filtered: 160,366/39,800,000 (0.40%)\n",
      "  Processed 39,900,000 lines | Filtered: 160,616/39,900,000 (0.40%)\n",
      "  Processed 40,000,000 lines | Filtered: 160,980/40,000,000 (0.40%)\n",
      "  Processed 40,100,000 lines | Filtered: 161,316/40,100,000 (0.40%)\n",
      "  Processed 40,200,000 lines | Filtered: 161,608/40,200,000 (0.40%)\n",
      "  Processed 40,300,000 lines | Filtered: 161,886/40,300,000 (0.40%)\n",
      "  Processed 40,400,000 lines | Filtered: 162,113/40,400,000 (0.40%)\n",
      "  Processed 40,500,000 lines | Filtered: 162,387/40,500,000 (0.40%)\n",
      "  Processed 40,600,000 lines | Filtered: 162,654/40,600,000 (0.40%)\n",
      "  Processed 40,700,000 lines | Filtered: 162,995/40,700,000 (0.40%)\n",
      "  Processed 40,800,000 lines | Filtered: 163,236/40,800,000 (0.40%)\n",
      "  Processed 40,900,000 lines | Filtered: 163,581/40,900,000 (0.40%)\n",
      "  Processed 41,000,000 lines | Filtered: 163,849/41,000,000 (0.40%)\n",
      "  Processed 41,100,000 lines | Filtered: 164,065/41,100,000 (0.40%)\n",
      "  Processed 41,200,000 lines | Filtered: 164,322/41,200,000 (0.40%)\n",
      "  Processed 41,300,000 lines | Filtered: 164,615/41,300,000 (0.40%)\n",
      "  Processed 41,400,000 lines | Filtered: 164,995/41,400,000 (0.40%)\n",
      "  Processed 41,500,000 lines | Filtered: 165,239/41,500,000 (0.40%)\n",
      "  Processed 41,600,000 lines | Filtered: 165,482/41,600,000 (0.40%)\n",
      "  Processed 41,700,000 lines | Filtered: 165,721/41,700,000 (0.40%)\n",
      "  Processed 41,800,000 lines | Filtered: 165,994/41,800,000 (0.40%)\n",
      "  Processed 41,900,000 lines | Filtered: 166,302/41,900,000 (0.40%)\n",
      "  Processed 42,000,000 lines | Filtered: 166,538/42,000,000 (0.40%)\n",
      "  Processed 42,100,000 lines | Filtered: 166,863/42,100,000 (0.40%)\n",
      "  Processed 42,200,000 lines | Filtered: 167,080/42,200,000 (0.40%)\n",
      "  Processed 42,300,000 lines | Filtered: 167,306/42,300,000 (0.40%)\n",
      "  Processed 42,400,000 lines | Filtered: 167,581/42,400,000 (0.40%)\n",
      "  Processed 42,500,000 lines | Filtered: 167,816/42,500,000 (0.39%)\n",
      "  Processed 42,600,000 lines | Filtered: 168,062/42,600,000 (0.39%)\n",
      "  Processed 42,700,000 lines | Filtered: 168,364/42,700,000 (0.39%)\n",
      "  Processed 42,800,000 lines | Filtered: 168,814/42,800,000 (0.39%)\n",
      "  Processed 42,900,000 lines | Filtered: 169,048/42,900,000 (0.39%)\n",
      "  Processed 43,000,000 lines | Filtered: 169,282/43,000,000 (0.39%)\n",
      "  Processed 43,100,000 lines | Filtered: 169,519/43,100,000 (0.39%)\n",
      "  Processed 43,200,000 lines | Filtered: 169,782/43,200,000 (0.39%)\n",
      "  Processed 43,300,000 lines | Filtered: 169,991/43,300,000 (0.39%)\n",
      "  Processed 43,400,000 lines | Filtered: 170,271/43,400,000 (0.39%)\n",
      "  Processed 43,500,000 lines | Filtered: 170,570/43,500,000 (0.39%)\n",
      "  Processed 43,600,000 lines | Filtered: 170,832/43,600,000 (0.39%)\n",
      "  Processed 43,700,000 lines | Filtered: 171,065/43,700,000 (0.39%)\n",
      "  Processed 43,800,000 lines | Filtered: 171,352/43,800,000 (0.39%)\n",
      "  Part 0: 171,573 rows â†’ s3://mlops-backblaze-d7b30cb5-us-east-1/raw/reviews_2023_parquet/raw_review_Electronics/part-000000.parquet\n",
      "\n",
      "âœ… Complete!\n",
      "   Total reviews processed: 43,886,944\n",
      "   Hard drive reviews (WD/Toshiba/Seagate/Hitachi): 171,573 (0.39%)\n",
      "   Parquet files created: 1\n",
      "   S3 location: s3://mlops-backblaze-d7b30cb5-us-east-1/raw/reviews_2023_parquet/raw_review_Electronics/\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfFileSystem\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "from io import BytesIO\n",
    "import json\n",
    "\n",
    "# Initialize HF filesystem\n",
    "hf_fs = HfFileSystem()\n",
    "\n",
    "dataset_name = HF_DATASET\n",
    "\n",
    "# Find Electronics review file\n",
    "print(\"Finding Electronics review file...\")\n",
    "review_path = f\"datasets/{dataset_name}/raw/review_categories\"\n",
    "review_files = hf_fs.ls(review_path, detail=True)\n",
    "electronics_files = [f for f in review_files if 'Electronics' in f['name']]\n",
    "\n",
    "if not electronics_files:\n",
    "    print(\"No Electronics files found\")\n",
    "else:\n",
    "    file_info = electronics_files[0]\n",
    "    file_path = file_info['name']\n",
    "    file_name = Path(file_path).name\n",
    "    \n",
    "    print(f\"Found: {file_name}\")\n",
    "    print(f\"Size: {file_info['size'] / 1024 / 1024:.2f} MB\")\n",
    "    \n",
    "    # First pass: Count total rows in JSONL file\n",
    "    print(f\"\\nCounting total rows in JSONL file...\")\n",
    "    total_lines = 0\n",
    "    with hf_fs.open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                total_lines += 1\n",
    "            if total_lines % 500000 == 0:\n",
    "                print(f\"  Counted {total_lines:,} rows...\")\n",
    "    \n",
    "    print(f\"Total rows in JSONL file: {total_lines:,}\\n\")\n",
    "    \n",
    "    # Second pass: Stream JSONL from HF, convert to Parquet, upload directly to S3\n",
    "    # This avoids filling up local disk\n",
    "    # Filter for hard drive manufacturers: Western Digital, Toshiba, Seagate, Hitachi\n",
    "    print(f\"Streaming JSONL -> Parquet -> S3 (filtering for hard drive brands)...\")\n",
    "    \n",
    "    # Define target brands for filtering (case-insensitive)\n",
    "    TARGET_BRANDS = ['western digital', 'wd', 'toshiba', 'seagate', 'hitachi', 'hgst', 'wdc']\n",
    "    \n",
    "    def is_hard_drive_review(review_data):\n",
    "        \"\"\"Check if review is for Western Digital, Toshiba, Seagate, or Hitachi storage drives\"\"\"\n",
    "        # Check in title, text, and parent_asin fields\n",
    "        search_fields = []\n",
    "        \n",
    "        if 'title' in review_data and review_data['title']:\n",
    "            search_fields.append(str(review_data['title']).lower())\n",
    "        if 'text' in review_data and review_data['text']:\n",
    "            search_fields.append(str(review_data['text']).lower())\n",
    "        if 'parent_asin' in review_data:\n",
    "            search_fields.append(str(review_data['parent_asin']).lower())\n",
    "        \n",
    "        # Combine all searchable text\n",
    "        search_text = ' '.join(search_fields)\n",
    "        \n",
    "        # Check if any target brand appears in the text\n",
    "        for brand in TARGET_BRANDS:\n",
    "            if brand in search_text:\n",
    "                # Additional check for storage-related keywords\n",
    "                storage_keywords = ['hard drive', 'hdd', 'ssd', 'drive', 'storage', 'disk', 'external drive', 'internal drive']\n",
    "                if any(keyword in search_text for keyword in storage_keywords):\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    chunk_size = 200_000\n",
    "    part_idx = 0\n",
    "    buffer = []\n",
    "    total_rows = 0\n",
    "    filtered_rows = 0\n",
    "    \n",
    "    # Open the JSONL file from HF\n",
    "    with hf_fs.open(file_path, 'r') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line.strip():\n",
    "                review_data = json.loads(line)\n",
    "                total_rows += 1\n",
    "                \n",
    "                # Filter for hard drive brands\n",
    "                if is_hard_drive_review(review_data):\n",
    "                    buffer.append(review_data)\n",
    "                    filtered_rows += 1\n",
    "                \n",
    "                # When buffer reaches chunk_size, write to parquet and upload\n",
    "                if len(buffer) >= chunk_size:\n",
    "                    df = pd.DataFrame(buffer)\n",
    "                    table = pa.Table.from_pandas(df, preserve_index=False)\n",
    "                    \n",
    "                    # Write to memory buffer\n",
    "                    buf = BytesIO()\n",
    "                    pq.write_table(table, buf, compression=\"snappy\")\n",
    "                    buf.seek(0)\n",
    "                    \n",
    "                    # Upload directly to S3\n",
    "                    s3_key = s3_reviews_out.replace(f\"s3://{bucket}/\", \"\") + f\"part-{part_idx:06d}.parquet\"\n",
    "                    s3.put_object(Bucket=bucket, Key=s3_key, Body=buf.getvalue())\n",
    "                    \n",
    "                    print(f\"  Part {part_idx}: {len(buffer):,} rows â†’ s3://{bucket}/{s3_key}\")\n",
    "                    \n",
    "                    # Clear buffer\n",
    "                    buffer = []\n",
    "                    part_idx += 1\n",
    "            \n",
    "            # Progress update every 100k lines\n",
    "            if (line_num + 1) % 100000 == 0:\n",
    "                print(f\"  Processed {line_num + 1:,} lines | Filtered: {filtered_rows:,}/{total_rows:,} ({100*filtered_rows/total_rows:.2f}%)\")\n",
    "    \n",
    "    # Write remaining buffer\n",
    "    if buffer:\n",
    "        df = pd.DataFrame(buffer)\n",
    "        table = pa.Table.from_pandas(df, preserve_index=False)\n",
    "        \n",
    "        buf = BytesIO()\n",
    "        pq.write_table(table, buf, compression=\"snappy\")\n",
    "        buf.seek(0)\n",
    "        \n",
    "        s3_key = s3_reviews_out.replace(f\"s3://{bucket}/\", \"\") + f\"part-{part_idx:06d}.parquet\"\n",
    "        s3.put_object(Bucket=bucket, Key=s3_key, Body=buf.getvalue())\n",
    "        \n",
    "        print(f\"  Part {part_idx}: {len(buffer):,} rows â†’ s3://{bucket}/{s3_key}\")\n",
    "    \n",
    "    print(f\"\\n Complete!\")\n",
    "    print(f\"   Total reviews processed: {total_rows:,}\")\n",
    "    print(f\"   Hard drive reviews (WD/Toshiba/Seagate/Hitachi): {filtered_rows:,} ({100*filtered_rows/total_rows:.2f}%)\")\n",
    "    print(f\"   Parquet files created: {part_idx + 1}\")\n",
    "    print(f\"   S3 location: {s3_reviews_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd6d3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking S3 bucket structure...\n",
      "\n",
      "1. Raw Backblaze ZIPs:\n",
      "   raw/backblaze/zips/data_Q1_2024.zip                              959.88 MB\n",
      "   raw/backblaze/zips/data_Q1_2025.zip                              973.21 MB\n",
      "   raw/backblaze/zips/data_Q2_2024.zip                              973.38 MB\n",
      "   raw/backblaze/zips/data_Q2_2025.zip                             1018.11 MB\n",
      "   raw/backblaze/zips/data_Q3_2024.zip                             1000.73 MB\n",
      "\n",
      "2. Curated Backblaze Parquet:\n",
      "   curated/backblaze_parquet/year=._2024/month=01/day=01/data_Q1_2024_01.parquet       1044 bytes\n",
      "   curated/backblaze_parquet/year=._2024/month=01/day=02/data_Q1_2024_02.parquet       1044 bytes\n",
      "   curated/backblaze_parquet/year=._2024/month=01/day=03/data_Q1_2024_03.parquet       1044 bytes\n",
      "   curated/backblaze_parquet/year=._2024/month=01/day=04/data_Q1_2024_04.parquet       1044 bytes\n",
      "   curated/backblaze_parquet/year=._2024/month=01/day=05/data_Q1_2024_05.parquet       1044 bytes\n",
      "   curated/backblaze_parquet/year=._2024/month=01/day=06/data_Q1_2024_06.parquet       1044 bytes\n",
      "   curated/backblaze_parquet/year=._2024/month=01/day=07/data_Q1_2024_07.parquet       1044 bytes\n",
      "   curated/backblaze_parquet/year=._2024/month=01/day=08/data_Q1_2024_08.parquet       1044 bytes\n",
      "   curated/backblaze_parquet/year=._2024/month=01/day=09/data_Q1_2024_09.parquet       1044 bytes\n",
      "   curated/backblaze_parquet/year=._2024/month=01/day=10/data_Q1_2024_10.parquet       1044 bytes\n",
      "\n",
      "3. Let's manually convert one CSV from a ZIP file:\n",
      "\n",
      "   Reading ZIP: raw/backblaze/zips/data_Q1_2024.zip\n",
      "   Found 182 CSV files in ZIP\n",
      "   Reading CSV: data_Q1_2024/2024-01-13.csv\n",
      "\n",
      "âœ… Loaded DataFrame from CSV:\n",
      "   Shape: (271976, 193) (rows Ã— columns)\n",
      "   Memory: 409.12 MB\n",
      "\n",
      "Columns (193 total):\n",
      "['date', 'serial_number', 'model', 'capacity_bytes', 'failure', 'datacenter', 'cluster_id', 'vault_id', 'pod_id', 'pod_slot_num', 'is_legacy_format', 'smart_1_normalized', 'smart_1_raw', 'smart_2_normalized', 'smart_2_raw']\n",
      "   ... and 178 more\n",
      "\n",
      "First 3 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>serial_number</th>\n",
       "      <th>model</th>\n",
       "      <th>capacity_bytes</th>\n",
       "      <th>failure</th>\n",
       "      <th>datacenter</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>vault_id</th>\n",
       "      <th>pod_id</th>\n",
       "      <th>pod_slot_num</th>\n",
       "      <th>...</th>\n",
       "      <th>smart_250_normalized</th>\n",
       "      <th>smart_250_raw</th>\n",
       "      <th>smart_251_normalized</th>\n",
       "      <th>smart_251_raw</th>\n",
       "      <th>smart_252_normalized</th>\n",
       "      <th>smart_252_raw</th>\n",
       "      <th>smart_254_normalized</th>\n",
       "      <th>smart_254_raw</th>\n",
       "      <th>smart_255_normalized</th>\n",
       "      <th>smart_255_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-13</td>\n",
       "      <td>WD-WX31DB48X22V</td>\n",
       "      <td>WDC WD60EFRX</td>\n",
       "      <td>6001175126016</td>\n",
       "      <td>0</td>\n",
       "      <td>sac0</td>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-13</td>\n",
       "      <td>Z4D00WGP</td>\n",
       "      <td>ST6000DX000</td>\n",
       "      <td>6001175126016</td>\n",
       "      <td>0</td>\n",
       "      <td>sac0</td>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-13</td>\n",
       "      <td>Z4D00YC6</td>\n",
       "      <td>ST6000DX000</td>\n",
       "      <td>6001175126016</td>\n",
       "      <td>0</td>\n",
       "      <td>sac0</td>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    serial_number         model  capacity_bytes  failure  \\\n",
       "0  2024-01-13  WD-WX31DB48X22V  WDC WD60EFRX   6001175126016        0   \n",
       "1  2024-01-13         Z4D00WGP   ST6000DX000   6001175126016        0   \n",
       "2  2024-01-13         Z4D00YC6   ST6000DX000   6001175126016        0   \n",
       "\n",
       "  datacenter  cluster_id  vault_id  pod_id  pod_slot_num  ...  \\\n",
       "0       sac0           0      1002       0          24.0  ...   \n",
       "1       sac0           0      1002       0          15.0  ...   \n",
       "2       sac0           0      1002       0           8.0  ...   \n",
       "\n",
       "   smart_250_normalized  smart_250_raw  smart_251_normalized  smart_251_raw  \\\n",
       "0                   NaN            NaN                   NaN            NaN   \n",
       "1                   NaN            NaN                   NaN            NaN   \n",
       "2                   NaN            NaN                   NaN            NaN   \n",
       "\n",
       "   smart_252_normalized  smart_252_raw  smart_254_normalized  smart_254_raw  \\\n",
       "0                   NaN            NaN                   NaN            NaN   \n",
       "1                   NaN            NaN                   NaN            NaN   \n",
       "2                   NaN            NaN                   NaN            NaN   \n",
       "\n",
       "   smart_255_normalized  smart_255_raw  \n",
       "0                   NaN            NaN  \n",
       "1                   NaN            NaN  \n",
       "2                   NaN            NaN  \n",
       "\n",
       "[3 rows x 193 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcdaa84a",
   "metadata": {},
   "source": [
    "## Read Sample Backblaze Parquet File from S3\n",
    "\n",
    "Read a sample parquet file from the curated Backblaze data in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c1257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading sample file: s3://mlops-backblaze-d7b30cb5-us-east-1/curated/backblaze_parquet/year=2025/month=01/day=01/data_Q1_2025_01.parquet\n",
      "\n",
      "Dataframe shape: (304957, 197)\n",
      "\n",
      "Columns: ['date', 'serial_number', 'model', 'capacity_bytes', 'failure', 'datacenter', 'cluster_id', 'vault_id', 'pod_id', 'pod_slot_num', 'is_legacy_format', 'smart_1_normalized', 'smart_1_raw', 'smart_2_normalized', 'smart_2_raw', 'smart_3_normalized', 'smart_3_raw', 'smart_4_normalized', 'smart_4_raw', 'smart_5_normalized', 'smart_5_raw', 'smart_7_normalized', 'smart_7_raw', 'smart_8_normalized', 'smart_8_raw', 'smart_9_normalized', 'smart_9_raw', 'smart_10_normalized', 'smart_10_raw', 'smart_11_normalized', 'smart_11_raw', 'smart_12_normalized', 'smart_12_raw', 'smart_13_normalized', 'smart_13_raw', 'smart_15_normalized', 'smart_15_raw', 'smart_16_normalized', 'smart_16_raw', 'smart_17_normalized', 'smart_17_raw', 'smart_18_normalized', 'smart_18_raw', 'smart_22_normalized', 'smart_22_raw', 'smart_23_normalized', 'smart_23_raw', 'smart_24_normalized', 'smart_24_raw', 'smart_27_normalized', 'smart_27_raw', 'smart_71_normalized', 'smart_71_raw', 'smart_82_normalized', 'smart_82_raw', 'smart_90_normalized', 'smart_90_raw', 'smart_160_normalized', 'smart_160_raw', 'smart_161_normalized', 'smart_161_raw', 'smart_163_normalized', 'smart_163_raw', 'smart_164_normalized', 'smart_164_raw', 'smart_165_normalized', 'smart_165_raw', 'smart_166_normalized', 'smart_166_raw', 'smart_167_normalized', 'smart_167_raw', 'smart_168_normalized', 'smart_168_raw', 'smart_169_normalized', 'smart_169_raw', 'smart_170_normalized', 'smart_170_raw', 'smart_171_normalized', 'smart_171_raw', 'smart_172_normalized', 'smart_172_raw', 'smart_173_normalized', 'smart_173_raw', 'smart_174_normalized', 'smart_174_raw', 'smart_175_normalized', 'smart_175_raw', 'smart_176_normalized', 'smart_176_raw', 'smart_177_normalized', 'smart_177_raw', 'smart_178_normalized', 'smart_178_raw', 'smart_179_normalized', 'smart_179_raw', 'smart_180_normalized', 'smart_180_raw', 'smart_181_normalized', 'smart_181_raw', 'smart_182_normalized', 'smart_182_raw', 'smart_183_normalized', 'smart_183_raw', 'smart_184_normalized', 'smart_184_raw', 'smart_187_normalized', 'smart_187_raw', 'smart_188_normalized', 'smart_188_raw', 'smart_189_normalized', 'smart_189_raw', 'smart_190_normalized', 'smart_190_raw', 'smart_191_normalized', 'smart_191_raw', 'smart_192_normalized', 'smart_192_raw', 'smart_193_normalized', 'smart_193_raw', 'smart_194_normalized', 'smart_194_raw', 'smart_195_normalized', 'smart_195_raw', 'smart_196_normalized', 'smart_196_raw', 'smart_197_normalized', 'smart_197_raw', 'smart_198_normalized', 'smart_198_raw', 'smart_199_normalized', 'smart_199_raw', 'smart_200_normalized', 'smart_200_raw', 'smart_201_normalized', 'smart_201_raw', 'smart_202_normalized', 'smart_202_raw', 'smart_206_normalized', 'smart_206_raw', 'smart_210_normalized', 'smart_210_raw', 'smart_211_normalized', 'smart_211_raw', 'smart_212_normalized', 'smart_212_raw', 'smart_218_normalized', 'smart_218_raw', 'smart_220_normalized', 'smart_220_raw', 'smart_222_normalized', 'smart_222_raw', 'smart_223_normalized', 'smart_223_raw', 'smart_224_normalized', 'smart_224_raw', 'smart_225_normalized', 'smart_225_raw', 'smart_226_normalized', 'smart_226_raw', 'smart_230_normalized', 'smart_230_raw', 'smart_231_normalized', 'smart_231_raw', 'smart_232_normalized', 'smart_232_raw', 'smart_233_normalized', 'smart_233_raw', 'smart_234_normalized', 'smart_234_raw', 'smart_235_normalized', 'smart_235_raw', 'smart_240_normalized', 'smart_240_raw', 'smart_241_normalized', 'smart_241_raw', 'smart_242_normalized', 'smart_242_raw', 'smart_244_normalized', 'smart_244_raw', 'smart_245_normalized', 'smart_245_raw', 'smart_246_normalized', 'smart_246_raw', 'smart_247_normalized', 'smart_247_raw', 'smart_248_normalized', 'smart_248_raw', 'smart_250_normalized', 'smart_250_raw', 'smart_251_normalized', 'smart_251_raw', 'smart_252_normalized', 'smart_252_raw', 'smart_254_normalized', 'smart_254_raw', 'smart_255_normalized', 'smart_255_raw']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>serial_number</th>\n",
       "      <th>model</th>\n",
       "      <th>capacity_bytes</th>\n",
       "      <th>failure</th>\n",
       "      <th>datacenter</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>vault_id</th>\n",
       "      <th>pod_id</th>\n",
       "      <th>pod_slot_num</th>\n",
       "      <th>...</th>\n",
       "      <th>smart_250_normalized</th>\n",
       "      <th>smart_250_raw</th>\n",
       "      <th>smart_251_normalized</th>\n",
       "      <th>smart_251_raw</th>\n",
       "      <th>smart_252_normalized</th>\n",
       "      <th>smart_252_raw</th>\n",
       "      <th>smart_254_normalized</th>\n",
       "      <th>smart_254_raw</th>\n",
       "      <th>smart_255_normalized</th>\n",
       "      <th>smart_255_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2207E60CC65A</td>\n",
       "      <td>CT250MX500SSD1</td>\n",
       "      <td>250059350016</td>\n",
       "      <td>0</td>\n",
       "      <td>sac0</td>\n",
       "      <td>0</td>\n",
       "      <td>1028</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2340E87B92B5</td>\n",
       "      <td>CT250MX500SSD1</td>\n",
       "      <td>250059350016</td>\n",
       "      <td>0</td>\n",
       "      <td>sac0</td>\n",
       "      <td>0</td>\n",
       "      <td>1028</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2EGK64VX</td>\n",
       "      <td>HGST HUH728080ALE604</td>\n",
       "      <td>8001563222016</td>\n",
       "      <td>0</td>\n",
       "      <td>sac0</td>\n",
       "      <td>0</td>\n",
       "      <td>1028</td>\n",
       "      <td>4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2EHZAKAX</td>\n",
       "      <td>HGST HUH728080ALE604</td>\n",
       "      <td>8001563222016</td>\n",
       "      <td>0</td>\n",
       "      <td>sac0</td>\n",
       "      <td>0</td>\n",
       "      <td>1028</td>\n",
       "      <td>12</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2EJ02A1X</td>\n",
       "      <td>HGST HUH728080ALE604</td>\n",
       "      <td>8001563222016</td>\n",
       "      <td>0</td>\n",
       "      <td>sac0</td>\n",
       "      <td>0</td>\n",
       "      <td>1028</td>\n",
       "      <td>10</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date serial_number                 model  capacity_bytes  failure  \\\n",
       "0  2025-01-01  2207E60CC65A        CT250MX500SSD1    250059350016        0   \n",
       "1  2025-01-01  2340E87B92B5        CT250MX500SSD1    250059350016        0   \n",
       "2  2025-01-01      2EGK64VX  HGST HUH728080ALE604   8001563222016        0   \n",
       "3  2025-01-01      2EHZAKAX  HGST HUH728080ALE604   8001563222016        0   \n",
       "4  2025-01-01      2EJ02A1X  HGST HUH728080ALE604   8001563222016        0   \n",
       "\n",
       "  datacenter  cluster_id  vault_id  pod_id  pod_slot_num  ...  \\\n",
       "0       sac0           0      1028      13           NaN  ...   \n",
       "1       sac0           0      1028      14           NaN  ...   \n",
       "2       sac0           0      1028       4          12.0  ...   \n",
       "3       sac0           0      1028      12          30.0  ...   \n",
       "4       sac0           0      1028      10          14.0  ...   \n",
       "\n",
       "   smart_250_normalized  smart_250_raw  smart_251_normalized  smart_251_raw  \\\n",
       "0                   NaN            NaN                   NaN            NaN   \n",
       "1                   NaN            NaN                   NaN            NaN   \n",
       "2                   NaN            NaN                   NaN            NaN   \n",
       "3                   NaN            NaN                   NaN            NaN   \n",
       "4                   NaN            NaN                   NaN            NaN   \n",
       "\n",
       "   smart_252_normalized  smart_252_raw  smart_254_normalized  smart_254_raw  \\\n",
       "0                   NaN            NaN                   NaN            NaN   \n",
       "1                   NaN            NaN                   NaN            NaN   \n",
       "2                   NaN            NaN                   NaN            NaN   \n",
       "3                   NaN            NaN                   NaN            NaN   \n",
       "4                   NaN            NaN                   NaN            NaN   \n",
       "\n",
       "   smart_255_normalized  smart_255_raw  \n",
       "0                   NaN            NaN  \n",
       "1                   NaN            NaN  \n",
       "2                   NaN            NaN  \n",
       "3                   NaN            NaN  \n",
       "4                   NaN            NaN  \n",
       "\n",
       "[5 rows x 197 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "from io import BytesIO\n",
    "\n",
    "# List files in the S3 path\n",
    "s3_path = \"curated/backblaze_parquet/\"\n",
    "response = s3.list_objects_v2(Bucket=bucket, Prefix=s3_path, MaxKeys=10)\n",
    "\n",
    "if 'Contents' in response:\n",
    "    # Get the first parquet file\n",
    "    parquet_files = [obj['Key'] for obj in response['Contents'] if obj['Key'].endswith('.parquet')]\n",
    "    \n",
    "    if parquet_files:\n",
    "        sample_file = parquet_files[0]\n",
    "        print(f\"Reading sample file: s3://{bucket}/{sample_file}\")\n",
    "        \n",
    "        # Download and read the parquet file\n",
    "        obj = s3.get_object(Bucket=bucket, Key=sample_file)\n",
    "        buffer = BytesIO(obj['Body'].read())\n",
    "        \n",
    "        # Read into dataframe\n",
    "        df_backblaze = pd.read_parquet(buffer)\n",
    "        \n",
    "        print(f\"\\nDataframe shape: {df_backblaze.shape}\")\n",
    "        print(f\"\\nColumns: {list(df_backblaze.columns)}\")\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        display(df_backblaze.head())\n",
    "    else:\n",
    "        print(f\"No parquet files found in s3://{bucket}/{s3_path}\")\n",
    "else:\n",
    "    print(f\"No objects found in s3://{bucket}/{s3_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77588a13",
   "metadata": {},
   "source": [
    "## Read Sample Reviews Parquet File from S3\n",
    "\n",
    "Read a sample parquet file from the curated reviews data in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b4d1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading sample reviews file: s3://mlops-backblaze-d7b30cb5-us-east-1/raw/reviews_2023_parquet/raw_review_Electronics/part-000000.parquet\n",
      "\n",
      "Dataframe shape: (171573, 10)\n",
      "\n",
      "Columns: ['rating', 'title', 'text', 'images', 'asin', 'parent_asin', 'user_id', 'timestamp', 'helpful_vote', 'verified_purchase']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Great solid flash drive - Toshiba quality and ...</td>\n",
       "      <td>Not much can be said that hasn't been said in ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00IEZGU6G</td>\n",
       "      <td>B00WHEUS22</td>\n",
       "      <td>AFSKPY37N3C43SOI5IEXEK5JSIYA</td>\n",
       "      <td>1411650573000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>GREAT External Drive</td>\n",
       "      <td>great price  -  I already had a Seagate 4TB an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B01M00UHV8</td>\n",
       "      <td>B07454F4JH</td>\n",
       "      <td>AHGAOIZVODNHYMNCBV4DECZH42UQ</td>\n",
       "      <td>1494691925000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Long Term Life is Questionable; Seagate not go...</td>\n",
       "      <td>The first one of these I got was DOA, but Seag...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B01IEKG3TY</td>\n",
       "      <td>B01IEKG3TY</td>\n",
       "      <td>AFAIJYOUO3NAWLBDIKTQSC3DASWA</td>\n",
       "      <td>1472494627000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Compact Attractive, Quiet Unit</td>\n",
       "      <td>Several reviewers mentioned the difficulty in ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B002HKEQZ6</td>\n",
       "      <td>B002OB4DC4</td>\n",
       "      <td>AFAIJYOUO3NAWLBDIKTQSC3DASWA</td>\n",
       "      <td>1306211962000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Works perfectly</td>\n",
       "      <td>I had a WD blue M.2 SSD that kept dropping off...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B09JCD2CN6</td>\n",
       "      <td>B09JCD2CN6</td>\n",
       "      <td>AFJBKPK5W56XWSNPQU2WW66ISWYQ</td>\n",
       "      <td>1640360340432</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                              title  \\\n",
       "0     4.0  Great solid flash drive - Toshiba quality and ...   \n",
       "1     5.0                               GREAT External Drive   \n",
       "2     3.0  Long Term Life is Questionable; Seagate not go...   \n",
       "3     4.0                     Compact Attractive, Quiet Unit   \n",
       "4     5.0                                    Works perfectly   \n",
       "\n",
       "                                                text images        asin  \\\n",
       "0  Not much can be said that hasn't been said in ...     []  B00IEZGU6G   \n",
       "1  great price  -  I already had a Seagate 4TB an...     []  B01M00UHV8   \n",
       "2  The first one of these I got was DOA, but Seag...     []  B01IEKG3TY   \n",
       "3  Several reviewers mentioned the difficulty in ...     []  B002HKEQZ6   \n",
       "4  I had a WD blue M.2 SSD that kept dropping off...     []  B09JCD2CN6   \n",
       "\n",
       "  parent_asin                       user_id      timestamp  helpful_vote  \\\n",
       "0  B00WHEUS22  AFSKPY37N3C43SOI5IEXEK5JSIYA  1411650573000             0   \n",
       "1  B07454F4JH  AHGAOIZVODNHYMNCBV4DECZH42UQ  1494691925000             1   \n",
       "2  B01IEKG3TY  AFAIJYOUO3NAWLBDIKTQSC3DASWA  1472494627000             1   \n",
       "3  B002OB4DC4  AFAIJYOUO3NAWLBDIKTQSC3DASWA  1306211962000             1   \n",
       "4  B09JCD2CN6  AFJBKPK5W56XWSNPQU2WW66ISWYQ  1640360340432             0   \n",
       "\n",
       "   verified_purchase  \n",
       "0              False  \n",
       "1               True  \n",
       "2              False  \n",
       "3              False  \n",
       "4              False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List files in the reviews S3 path\n",
    "s3_reviews_path = \"raw/reviews_2023_parquet/raw_review_Electronics/\"\n",
    "response_reviews = s3.list_objects_v2(Bucket=bucket, Prefix=s3_reviews_path, MaxKeys=10)\n",
    "\n",
    "if 'Contents' in response_reviews:\n",
    "    # Get the first parquet file\n",
    "    reviews_parquet_files = [obj['Key'] for obj in response_reviews['Contents'] if obj['Key'].endswith('.parquet')]\n",
    "    \n",
    "    if reviews_parquet_files:\n",
    "        sample_reviews_file = reviews_parquet_files[0]\n",
    "        print(f\"Reading sample reviews file: s3://{bucket}/{sample_reviews_file}\")\n",
    "        \n",
    "        # Download and read the parquet file\n",
    "        obj_reviews = s3.get_object(Bucket=bucket, Key=sample_reviews_file)\n",
    "        buffer_reviews = BytesIO(obj_reviews['Body'].read())\n",
    "        \n",
    "        # Read into dataframe\n",
    "        df_reviews = pd.read_parquet(buffer_reviews)\n",
    "        \n",
    "        print(f\"\\nDataframe shape: {df_reviews.shape}\")\n",
    "        print(f\"\\nColumns: {list(df_reviews.columns)}\")\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        display(df_reviews.head())\n",
    "    else:\n",
    "        print(f\"No parquet files found in s3://{bucket}/{s3_reviews_path}\")\n",
    "else:\n",
    "    print(f\"No objects found in s3://{bucket}/{s3_reviews_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63456818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ASIN values: 45,735\n",
      "Unique parent_asin values: 40,965\n"
     ]
    }
   ],
   "source": [
    "# Count unique ASIN values\n",
    "unique_asin_count = df_reviews['asin'].nunique()\n",
    "print(f\"Unique ASIN values: {unique_asin_count:,}\")\n",
    "\n",
    "# Also show unique parent_asin if it exists\n",
    "if 'parent_asin' in df_reviews.columns:\n",
    "    unique_parent_asin_count = df_reviews['parent_asin'].nunique()\n",
    "    print(f\"Unique parent_asin values: {unique_parent_asin_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859957ba",
   "metadata": {},
   "source": [
    "## Examine Data for Joining\n",
    "\n",
    "Check sample values from both datasets to understand how to create a join key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146e589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Reviews Data:\n",
      "  parent_asin                                              title  \\\n",
      "0  B00WHEUS22  Great solid flash drive - Toshiba quality and ...   \n",
      "1  B07454F4JH                               GREAT External Drive   \n",
      "2  B01IEKG3TY  Long Term Life is Questionable; Seagate not go...   \n",
      "3  B002OB4DC4                     Compact Attractive, Quiet Unit   \n",
      "4  B09JCD2CN6                                    Works perfectly   \n",
      "5  B0C6QYPNYR                               Great for mobile use   \n",
      "6  B01FRP1ZHE                           Chic looking hard drive.   \n",
      "7  B01BCWKBZI                                    Fast and small.   \n",
      "8  B09VS4V18K                                                DOA   \n",
      "9  B018AX3OHO  This thing is even faster than my Macbook than...   \n",
      "\n",
      "                                                text  \n",
      "0  Not much can be said that hasn't been said in ...  \n",
      "1  great price  -  I already had a Seagate 4TB an...  \n",
      "2  The first one of these I got was DOA, but Seag...  \n",
      "3  Several reviewers mentioned the difficulty in ...  \n",
      "4  I had a WD blue M.2 SSD that kept dropping off...  \n",
      "5  I own a dell engineering workstation laptop Pr...  \n",
      "6  I like the look but actually causes some issue...  \n",
      "7  Fast and small. I was able to transfer 40 GBs ...  \n",
      "8  Iâ€™ve used WD drives before with no problems bu...  \n",
      "9  This thing is even faster than my Macbook than...  \n",
      "\n",
      "================================================================================\n",
      "\n",
      "Sample Backblaze Model Data:\n",
      "model\n",
      "TOSHIBA MG08ACA16TA     40129\n",
      "TOSHIBA MG07ACA14TA     37703\n",
      "ST16000NM001G           33600\n",
      "WDC WUH722222ALE6L4     30001\n",
      "WDC WUH721816ALE6L4     26395\n",
      "ST12000NM0008           19033\n",
      "ST8000NM0055            13532\n",
      "HGST HUH721212ALE604    13312\n",
      "ST12000NM001G           13168\n",
      "ST14000NM001G           10589\n",
      "HGST HUH721212ALN604    10192\n",
      "ST8000DM002              9077\n",
      "WDC WUH721414ALE6L4      8546\n",
      "TOSHIBA MG10ACA20TE      5943\n",
      "TOSHIBA MG08ACA16TE      5912\n",
      "TOSHIBA MG08ACA16TEY     5163\n",
      "HGST HMS5C4040BLE640     4114\n",
      "WDC WUH721816ALE6L0      3016\n",
      "HGST HUH721212ALE600     2606\n",
      "ST14000NM0138            1321\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sample review titles and parent_asin to see product names\n",
    "print(\"Sample Reviews Data:\")\n",
    "print(df_reviews[['parent_asin', 'title', 'text']].head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Sample backblaze model names\n",
    "print(\"Sample Backblaze Model Data:\")\n",
    "print(df_backblaze['model'].value_counts().head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818a1c9a",
   "metadata": {},
   "source": [
    "## Create Join Keys\n",
    "\n",
    "Extract manufacturer and model information from reviews to match with Backblaze model data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "189bd518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews with manufacturer extracted:\n",
      "  parent_asin                                              title manufacturer  \\\n",
      "0  B00WHEUS22  Great solid flash drive - Toshiba quality and ...      TOSHIBA   \n",
      "1  B07454F4JH                               GREAT External Drive      SEAGATE   \n",
      "2  B01IEKG3TY  Long Term Life is Questionable; Seagate not go...      SEAGATE   \n",
      "3  B002OB4DC4                     Compact Attractive, Quiet Unit      SEAGATE   \n",
      "4  B09JCD2CN6                                    Works perfectly          WDC   \n",
      "5  B0C6QYPNYR                               Great for mobile use          WDC   \n",
      "6  B01FRP1ZHE                           Chic looking hard drive.          WDC   \n",
      "7  B01BCWKBZI                                    Fast and small.          WDC   \n",
      "8  B09VS4V18K                                                DOA          WDC   \n",
      "9  B018AX3OHO  This thing is even faster than my Macbook than...          WDC   \n",
      "\n",
      "                                         model_hints  \n",
      "0                  [TOSHIBA QUALITY, AND DURABILITY]  \n",
      "1                                   [GREAT EXTERNAL]  \n",
      "2                    [IS QUESTIONABLE, GOOD QUALITY]  \n",
      "3                               [COMPACT ATTRACTIVE]  \n",
      "4                                  [WORKS PERFECTLY]  \n",
      "5                                       [FOR MOBILE]  \n",
      "6                                     [CHIC LOOKING]  \n",
      "7  [TO TRANSFER, OLDER DESKTOP, PCI EXPRESS, GET ...  \n",
      "8  [WD DRIVES, NO PROBLEMS, ONE ARRIVED, BE RETUR...  \n",
      "9                          [EVEN FASTER, MY MACBOOK]  \n",
      "\n",
      "Reviews with manufacturer identified: 163,406 / 171,573\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Backblaze with manufacturer extracted:\n",
      "                                model manufacturer\n",
      "0                      CT250MX500SSD1         None\n",
      "1                      CT250MX500SSD1         None\n",
      "2                HGST HUH728080ALE604         HGST\n",
      "3                HGST HUH728080ALE604         HGST\n",
      "4                HGST HUH728080ALE604         HGST\n",
      "5  Seagate BarraCuda SSD ZA250CM10002         None\n",
      "6                       ST500LM012 HN      SEAGATE\n",
      "7                       ST500LM012 HN      SEAGATE\n",
      "8                       ST500LM012 HN      SEAGATE\n",
      "9                       ST500LM012 HN      SEAGATE\n",
      "\n",
      "Manufacturer distribution in Backblaze:\n",
      "manufacturer\n",
      "SEAGATE    105834\n",
      "TOSHIBA     95959\n",
      "WDC         68377\n",
      "HGST        31654\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_manufacturer(text):\n",
    "    \"\"\"Extract manufacturer from review text\"\"\"\n",
    "    text_lower = str(text).lower()\n",
    "    \n",
    "    # Map various manufacturer names to standard format\n",
    "    if 'toshiba' in text_lower:\n",
    "        return 'TOSHIBA'\n",
    "    elif 'seagate' in text_lower or 'st' in text_lower[:3]:\n",
    "        return 'SEAGATE'\n",
    "    elif 'western digital' in text_lower or 'wd' in text_lower or 'wdc' in text_lower:\n",
    "        return 'WDC'\n",
    "    elif 'hitachi' in text_lower or 'hgst' in text_lower:\n",
    "        return 'HGST'\n",
    "    \n",
    "    return None\n",
    "\n",
    "def extract_model_hints(text):\n",
    "    \"\"\"Extract potential model numbers/patterns from review text\"\"\"\n",
    "    text_upper = str(text).upper()\n",
    "    \n",
    "    # Look for common model patterns\n",
    "    patterns = [\n",
    "        r'[A-Z]{2,}\\s*[A-Z0-9]{6,}',  # e.g., \"MG08ACA16TA\", \"WUH722222ALE6L4\"\n",
    "        r'ST\\d{4,}[A-Z]{2}\\d{3,}[A-Z]?',  # Seagate pattern\n",
    "        r'WD[A-Z0-9]{6,}',  # WD pattern\n",
    "        r'MG\\d{2}[A-Z]{3}\\d{2}[A-Z]{2,}',  # Toshiba pattern\n",
    "    ]\n",
    "    \n",
    "    models = []\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text_upper)\n",
    "        models.extend(matches)\n",
    "    \n",
    "    return models if models else None\n",
    "\n",
    "# Add manufacturer and model hints to reviews dataframe\n",
    "df_reviews['manufacturer'] = df_reviews['title'].apply(extract_manufacturer)\n",
    "df_reviews['manufacturer'] = df_reviews['manufacturer'].fillna(\n",
    "    df_reviews['text'].apply(extract_manufacturer)\n",
    ")\n",
    "\n",
    "df_reviews['model_hints'] = df_reviews['title'].apply(extract_model_hints)\n",
    "df_reviews['model_hints'] = df_reviews['model_hints'].fillna(\n",
    "    df_reviews['text'].apply(extract_model_hints)\n",
    ")\n",
    "\n",
    "# Add manufacturer to backblaze data for easier joining\n",
    "def get_bb_manufacturer(model):\n",
    "    \"\"\"Extract manufacturer from Backblaze model name\"\"\"\n",
    "    if model.startswith('TOSHIBA'):\n",
    "        return 'TOSHIBA'\n",
    "    elif model.startswith('ST') or model.startswith('SEAGATE'):\n",
    "        return 'SEAGATE'\n",
    "    elif model.startswith('WDC') or model.startswith('WD'):\n",
    "        return 'WDC'\n",
    "    elif model.startswith('HGST') or model.startswith('HITACHI'):\n",
    "        return 'HGST'\n",
    "    return None\n",
    "\n",
    "df_backblaze['manufacturer'] = df_backblaze['model'].apply(get_bb_manufacturer)\n",
    "\n",
    "print(\"Reviews with manufacturer extracted:\")\n",
    "print(df_reviews[['parent_asin', 'title', 'manufacturer', 'model_hints']].head(10))\n",
    "print(f\"\\nReviews with manufacturer identified: {df_reviews['manufacturer'].notna().sum():,} / {len(df_reviews):,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Backblaze with manufacturer extracted:\")\n",
    "print(df_backblaze[['model', 'manufacturer']].head(10))\n",
    "print(f\"\\nManufacturer distribution in Backblaze:\")\n",
    "print(df_backblaze['manufacturer'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379c4625",
   "metadata": {},
   "source": [
    "## Join Strategy Summary\n",
    "\n",
    "Now both datasets have a `manufacturer` field that can be used for joining:\n",
    "\n",
    "- **Reviews**: `df_reviews['manufacturer']` - extracted from title/text (TOSHIBA, SEAGATE, WDC, HGST)\n",
    "- **Backblaze**: `df_backblaze['manufacturer']` - extracted from model name\n",
    "\n",
    "You can join on manufacturer to analyze reviews by manufacturer against Backblaze failure data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bca1817a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join Example - Reviews by Manufacturer:\n",
      "\n",
      "Reviews distribution:\n",
      "manufacturer\n",
      "WDC        103758\n",
      "SEAGATE     40251\n",
      "TOSHIBA     16134\n",
      "HGST         3263\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Backblaze distribution:\n",
      "manufacturer\n",
      "SEAGATE    105834\n",
      "TOSHIBA     95959\n",
      "WDC         68377\n",
      "HGST        31654\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Example join: Get reviews by manufacturer\n",
    "print(\"Join Example - Reviews by Manufacturer:\")\n",
    "print(\"\\nReviews distribution:\")\n",
    "print(df_reviews['manufacturer'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Backblaze distribution:\")\n",
    "print(df_backblaze['manufacturer'].value_counts())\n",
    "\n",
    "# You can now join like this:\n",
    "# joined_df = df_reviews.merge(df_backblaze, on='manufacturer', how='inner')\n",
    "# Or do aggregations by manufacturer before joining"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
